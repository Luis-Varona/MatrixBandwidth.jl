var documenterSearchIndex = {"docs":
[{"location":"public_api/#MatrixBandwidth.jl-–-Public-API","page":"Public API","title":"MatrixBandwidth.jl – Public API","text":"","category":"section"},{"location":"public_api/","page":"Public API","title":"Public API","text":"Documentation for MatrixBandwidth's public API.","category":"page"},{"location":"public_api/","page":"Public API","title":"Public API","text":"note: Note\nThe following documentation covers only the public API of the package. For internal details, see the private API documentation.","category":"page"},{"location":"public_api/#MatrixBandwidth.MatrixBandwidth","page":"Public API","title":"MatrixBandwidth.MatrixBandwidth","text":"MatrixBandwidth\n\n[TODO: Update to reflect recognition algorithms too]\n\nFast algorithms for matrix bandwidth minimization and matrix bandwidth recognition in Julia.\n\nThe bandwidth of a square matrix A is the minimum non-negative integer k  ℕ such that Ai j = 0 whenever i - j  k. Equivalently, A has bandwidth at most k if all entries above the k-th superdiagonal and below the k-th subdiagonal are zero, and A has bandwidth at least k if there exists any nonzero entry in the k-th superdiagonal or subdiagonal.\n\nThe matrix bandwidth minimization problem involves finding a permutation matrix P such that the bandwidth of PAPᵀ is minimized; this is known to be NP-complete. Several heuristic algorithms (such as reverse Cuthill–McKee) run in polynomial time while still producing near-optimal orderings in practice, but exact methods (like Caprara–Salazar-González) are exponential in time complexity and thus are only feasible for relatively small matrices.\n\nOn the other hand, the matrix bandwidth recognition problem entails determining whether there exists a permutation matrix P such that the bandwidth of PAPᵀ is at most some fixed non-negative integer k  ℕ—an optimal permutation that fully minimizes the bandwidth of A is not required. Unlike the NP-hard minimization problem, this is decidable in O(nᵏ) time, where n is the order of A.\n\nThe following algorithms are currently supported:\n\nMinimization\nExact\nCaprara–Salazar-González algorithm (Minimization.CapraraSalazarGonzalez)\nDel Corso–Manzini algorithm (Minimization.DelCorsoManzini)\nDel Corso–Manzini algorithm with perimeter search (Minimization.DelCorsoManziniWithPS)\nSaxe–Gurari–Sudborough algorithm (Minimization.SaxeGurariSudborough)\nHeuristic\nGibbs–Poole–Stockmeyer algorithm (Minimization.GibbsPooleStockmeyer)\nCuthill–McKee algorithm (Minimization.CuthillMcKee)\nReverse Cuthill–McKee algorithm (Minimization.ReverseCuthillMcKee)\nMetaheuristic\nGreedy randomized adaptive search procedure (GRASP) (Minimization.GRASP)\nSimulated annealing (Minimization.SimulatedAnnealing)\nGenetic algorithm (Minimization.GeneticAlgorithm)\nRecognition\nCaprara–Salazar-González algorithm (Recognition.CapraraSalazarGonzalez)\nDel Corso–Manzini algorith (Recognition.DelCorsoManzini)\nDel Corso–Manzini algorithm with perimeter search (Recognition.DelCorsoManziniWithPS)\nSaxe–Gurari–Sudborough algorithm (Recognition.SaxeGurariSudborough)\n\nFull documentation is available for the latest development version of this package.\n\n\n\n\n\n","category":"module"},{"location":"public_api/#MatrixBandwidth.bandwidth-Tuple{AbstractMatrix{<:Number}}","page":"Public API","title":"MatrixBandwidth.bandwidth","text":"bandwidth(A) -> Int\n\nCompute the bandwidth of A before any permutation of its rows and columns.\n\nThe bandwidth of a square matrix A is the minimum non-negative integer k  ℕ such that Ai j = 0 whenever i - j  k. Equivalently, A has bandwidth at most k if all entries above the k-th superdiagonal and below the k-th subdiagonal are zero, and A has bandwidth at least k if there exists any nonzero entry in the k-th superdiagonal or subdiagonal.\n\nIn contrast to minimize_bandwidth, this function does not attempt to minimize the bandwidth of A by permuting its rows and columns—it simply computes its bandwidth as is.\n\nArguments\n\nA::AbstractMatrix{<:Number}: the (square) matrix whose bandwidth is computed.\n\nReturns\n\n::Int: the bandwidth of A.\n\nPerformance\n\nGiven an nn input matrix A, this relatively simple algorithm runs in O(n²) time.\n\nExamples\n\nbandwidth correctly identifies the bandwidth of a pentadiagonal matrix as 2 and does not attempt to find a minimizing permutation upon shuffling of its rows and columns:\n\njulia> using Random\n\njulia> Random.seed!(242622);\n\njulia> (n, k) = (8, 2);\n\njulia> perm = randperm(n);\n\njulia> A = (!iszero).(random_banded_matrix(8, 2))\n8×8 BitMatrix:\n 1  0  0  0  0  0  0  0\n 0  1  0  1  0  0  0  0\n 0  0  0  1  1  0  0  0\n 0  1  1  1  0  1  0  0\n 0  0  1  0  0  0  0  0\n 0  0  0  1  0  0  0  0\n 0  0  0  0  0  0  0  0\n 0  0  0  0  0  0  0  0\n\njulia> bandwidth(A)\n2\n\njulia> A_shuffled = A[perm, perm]\n8×8 BitMatrix:\n 0  0  0  0  0  0  1  0\n 0  0  0  0  0  0  0  0\n 0  0  0  1  0  0  0  0\n 0  0  1  0  0  0  1  0\n 0  0  0  0  1  0  0  0\n 0  0  0  0  0  1  1  0\n 1  0  0  1  0  1  1  0\n 0  0  0  0  0  0  0  0\n\njulia> bandwidth(A_shuffled)\n6\n\nNotes\n\nSome texts define matrix bandwidth to be the minimum non-negative integer k such that Ai j = 0 whenever i - j  k instead, particularly in more mathematically-minded communities. Effectively, this definition treats diagonal matrices as bandwidth 1, tridiagonal matrices as bandwidth 2, and so on. Our definition, on the other hand, is more common in computer science contexts, treating diagonal matrices as bandwidth 0 and tridiagonal matrices as bandwidth 1. (Both definitions, however, agree that the bandwidth of an empty matrix is simply 0.)\n\n\n\n\n\n","category":"method"},{"location":"public_api/#MatrixBandwidth.bandwidth_lower_bound-Tuple{AbstractMatrix{<:Number}}","page":"Public API","title":"MatrixBandwidth.bandwidth_lower_bound","text":"bandwidth_lower_bound(A) -> Int\n\nCompute a lower bound on the bandwidth of A using [CS05]'s results.\n\nThe nonzero support of A is assumed to be symmetric, since [CS05]'s bound was discovered in the context of undirected graphs (whose adjacency matrices are symmetric).\n\nThe bandwidth of a square matrix A is the minimum non-negative integer k  ℕ such that Ai j = 0 whenever i - j  k. Equivalently, A has bandwidth at most k if all entries above the k-th superdiagonal and below the k-th subdiagonal are zero, and A has bandwidth at least k if there exists any nonzero entry in the k-th superdiagonal or subdiagonal.\n\nIn contrast to minimize_bandwidth, this function does not attempt to truly minimize the bandwidth of A—it simply returns a lower bound on its bandwidth up to symmetric permutation of its rows and columns. This bound is not tight, but it is easily computable in O(n³) time, dominated by the Floyd–Warshall algorithm call. (The core logic here runs in O(n²) time.)\n\nArguments\n\nA::AbstractMatrix{<:Number}: the (square) matrix on whose bandwidth a lower bound is to   be computed. A must have a symmetric nonzero support (i.e., A[i, j] is nonzero if   and only if A[j, i] is nonzero).\n\nReturns\n\n::Int: a lower bound on the bandwidth of A. (This bound is not tight.)\n\nExamples\n\nTODO: Write here\n\nNotes\n\nSome texts define matrix bandwidth to be the minimum non-negative integer k such that Ai j = 0 whenever i - j  k instead, particularly in more mathematically-minded communities. Effectively, this definition treats diagonal matrices as bandwidth 1, tridiagonal matrices as bandwidth 2, and so on. Our definition, on the other hand, is more common in computer science contexts, treating diagonal matrices as bandwidth 0 and tridiagonal matrices as bandwidth 1. (Both definitions, however, agree that the bandwidth of an empty matrix is simply 0.)\n\n\n\n\n\n","category":"method"},{"location":"public_api/#MatrixBandwidth.random_banded_matrix-Tuple{Int64, Int64}","page":"Public API","title":"MatrixBandwidth.random_banded_matrix","text":"random_banded_matrix(n, k; p=0.5, rng=default_rng()) -> Matrix{Float64}\n\nGenerate a random n×n structurally symmetric k-banded matrix with band density ≈ p.\n\nBy definition of structural symmetry, the (i j)-th entry of the matrix is nonzero if and only if the (j i)-th entry is nonzero as well. All entries from this matrix are from the interval [0, 1]. Entries up to the k-th superdiagonal and down to the k-th subdiagonal are nonzero with probability p.\n\nIt is also guaranteed that each of these bands (besides the main diagonal) has at least one nonzero entry (even when p is very small), thus ensuring that th matrix has bandwidth precisely k before any reordering. (There may, however, still exist a symmetric permutation inducing a minimum bandwidth less than k, especially for small values of p.)\n\nArguments\n\nn::Int: the order of the matrix to generate. Must be positive.\nk::Int: the desired matrix bandwidth. Must satisfy 0 ≤ k < n.\n\nKeyword Arguments\n\np::Real=0.5: the band density. Must satisfy 0 < p ≤ 1. Defaults to 0.5.\nrng::AbstractRNG=Random.default_rng(): the random number generator to use. Defaults to   Random.default_rng().\n\nReturns\n\n::Matrix{Float64}: a random n×n matrix with bandwidth exactly k and sparse bands   with density p.\n\nExamples\n\nGenerate a 66 matrix with bandwidth 1 and the maximum number of nonzero entries:\n\njulia> using Random\n\njulia> A = random_banded_matrix(6, 1; p=1, rng=MersenneTwister(1228))\n6×6 Matrix{Float64}:\n 0.310239  0.346413  0.0       0.0        0.0       0.0\n 0.509981  0.917073  0.390771  0.0        0.0       0.0\n 0.0       0.760045  0.808396  0.0195686  0.0       0.0\n 0.0       0.0       0.222338  0.853164   0.806888  0.0\n 0.0       0.0       0.0       0.421603   0.132165  0.805813\n 0.0       0.0       0.0       0.0        0.305339  0.0799183\n\njulia> bandwidth(A)\n1\n\nGenerate a 77 matrix with bandwidth 3 and band density 03:\n\njulia> using Random\n\njulia> A = random_banded_matrix(7, 3; p=0.3, rng=MersenneTwister(0402))\n7×7 Matrix{Float64}:\n 0.0       0.132699  0.0       0.0       0.0  0.0       0.0\n 0.869352  0.0       0.324319  0.926496  0.0  0.0       0.0\n 0.0       0.891878  0.0       0.658102  0.0  0.0       0.0\n 0.0       0.88859   0.399559  0.0       0.0  0.284285  0.703377\n 0.0       0.0       0.0       0.0       0.0  0.0       0.0\n 0.0       0.0       0.0       0.489594  0.0  0.0       0.393573\n 0.0       0.0       0.0       0.412412  0.0  0.47063   0.0\n\njulia> bandwidth(A)\n3\n\nGenerate an 88 diagonal (bandwidth 0) matrix with default band density (05):\n\njulia> using Random\n\njulia> A = random_banded_matrix(8, 0; rng=MersenneTwister(0102))\n8×8 Matrix{Float64}:\n 0.0  0.0        0.0       0.0       0.0  0.0      0.0  0.0\n 0.0  0.0762399  0.0       0.0       0.0  0.0      0.0  0.0\n 0.0  0.0        0.373113  0.0       0.0  0.0      0.0  0.0\n 0.0  0.0        0.0       0.726309  0.0  0.0      0.0  0.0\n 0.0  0.0        0.0       0.0       0.0  0.0      0.0  0.0\n 0.0  0.0        0.0       0.0       0.0  0.41974  0.0  0.0\n 0.0  0.0        0.0       0.0       0.0  0.0      0.0  0.0\n 0.0  0.0        0.0       0.0       0.0  0.0      0.0  0.293132\n\njulia> bandwidth(A)\n0\n\nNotes\n\nUsers of the MatrixBandwidth package may find this function useful when generating random test data for whatever frameworks, algorithms, etc. they are implementing.\n\n\n\n\n\n","category":"method"},{"location":"public_api/#MatrixBandwidth.Minimization","page":"Public API","title":"MatrixBandwidth.Minimization","text":"MatrixBandwidth.Minimization\n\nExact, heuristic, and metaheuristic algorithms for matrix bandwidth minimization in Julia.\n\nThe bandwidth of a square matrix A is the minimum non-negative integer k  ℕ such that Ai j = 0 whenever i - j  k. Equivalently, A has bandwidth at most k if all entries above the k-th superdiagonal and below the k-th subdiagonal are zero, and A has bandwidth at least k if there exists any nonzero entry in the k-th superdiagonal or subdiagonal.\n\nThe matrix bandwidth minimization problem involves finding a permutation matrix P such that the bandwidth of PAPᵀ is minimized; this is known to be NP-complete. Several heuristic algorithms (such as reverse Cuthill–McKee) run in polynomial time while still producing near-optimal orderings in practice, but exact methods (like Caprara–Salazar-González) are exponential in time complexity and thus are only feasible for relatively small matrices.\n\nThe following algorithms are currently supported:\n\nExact\nCaprara–Salazar-González algorithm (CapraraSalazarGonzalez)\nDel Corso–Manzini algorithm (DelCorsoManzini)\nDel Corso–Manzini algorithm with perimeter search (DelCorsoManziniWithPS)\nSaxe–Gurari–Sudborough algorithm (SaxeGurariSudborough)\nHeuristic\nGibbs–Poole–Stockmeyer algorithm (GibbsPooleStockmeyer)\nCuthill–McKee algorithm (CuthillMcKee)\nReverse Cuthill–McKee algorithm (ReverseCuthillMcKee)\nMetaheuristic\nGreedy randomized adaptive search procedure (GRASP) (GRASP)\nSimulated annealing (SimulatedAnnealing)\nGenetic algorithm (GeneticAlgorithm)\n\nThis submodule is part of the MatrixBandwidth.jl package.\n\n\n\n\n\n","category":"module"},{"location":"public_api/#MatrixBandwidth.Minimization.MinimizationResult","page":"Public API","title":"MatrixBandwidth.Minimization.MinimizationResult","text":"MinimizationResult{A,M,O} <: AbstractResult\n\nOutput struct for matrix bandwidth minimization results.\n\nFields\n\nalgorithm::A<:AbstractSolver: the solver used to minimize the bandwidth.\nmatrix::M<:AbstractMatrix{<:Number}: the original matrix whose bandwidth is minimized.\nordering::O<:Vector{Int}: the (near-)optimal ordering of the rows and columns.\nbandwidth::Int: the minimized bandwidth of the matrix.\napproach::Symbol: the approach used by the solver. (Should be one of :exact,   :heuristic, and :metaheuristic.)\n\nConstructors\n\nMinimizationResult(algorithm, matrix, ordering, bandwidth): constructs a new   MinimizationResult instance with the given fields. The approach field is   automatically determined based on the algorithm type.\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.minimize_bandwidth","page":"Public API","title":"MatrixBandwidth.Minimization.minimize_bandwidth","text":"minimize_bandwidth(A, solver=ReverseCuthillMcKee()) -> MinimizationResult\n\nMinimize the bandwidth of A using the algorithm defined by solver.\n\nThe bandwidth of a square matrix A is the minimum non-negative integer k  ℕ such that Ai j = 0 whenever i - j  k. Equivalently, A has bandwidth at most k if all entries above the k-th superdiagonal and below the k-th subdiagonal are zero, and A has bandwidth at least k if there exists any nonzero entry in the k-th superdiagonal or subdiagonal.\n\nThis function computes a (near-)optimal ordering π of the rows and columns of A so that the bandwidth of PAPᵀ is minimized, where P is the permutation matrix corresponding to π. This is known to be an NP-complete problem; however, several heuristic algorithms such as ReverseCuthillMcKee run in polynomial time while still producing near-optimal orderings in practice. Exact methods like CapraraSalazarGonzalez are also available, but they are exponential in time complexity and thus only feasible for relatively small matrices.\n\nArguments\n\nA::AbstractMatrix{<:Number}: the (square) matrix whose bandwidth is minimized.\nsolver::AbstractSolver: the matrix bandwidth minimization algorithm to use; defaults to   ReverseCuthillMcKee. (See the Minimization module documentation for   a full list of supported solvers.)\n\nReturns\n\n::MinimizationResult: a struct containing the original matrix A, the minimized   bandwidth, the (near-)optimal ordering of the rows and columns, and the algorithm used.\n\nExamples\n\n[TODO: Add here once more solvers are implemented]\n\nNotes\n\nSome texts define matrix bandwidth to be the minimum non-negative integer k such that Ai j = 0 whenever i - j  k instead, particularly in more mathematically-minded communities. Effectively, this definition treats diagonal matrices as bandwidth 1, tridiagonal matrices as bandwidth 2, and so on. Our definition, on the other hand, is more common in computer science contexts, treating diagonal matrices as bandwidth 0 and tridiagonal matrices as bandwidth 1. (Both definitions, however, agree that the bandwidth of an empty matrix is simply 0.)\n\n\n\n\n\n","category":"function"},{"location":"public_api/#MatrixBandwidth.Minimization.Exact","page":"Public API","title":"MatrixBandwidth.Minimization.Exact","text":"MatrixBandwidth.Minimization.Exact\n\nExact solvers for matrix bandwidth minimization.\n\nExact methods are those which guarantee an optimal ordering producing the true minimum bandwidth of a matrix. Since bandwidth minimization is an NP-complete problem, existing exact algorithms are, at best, exponential in time complexity—much worse than many polynomial-time heuristic approaches (e.g., reverse Cuthill–McKee). Such methods, therefore, are not feasible for large matrices, but they remain useful when precise solutions are required for small-to-medium-sized inputs (say, up to 100100).\n\nThe following exact algorithms are currently supported:\n\nCaprara–Salazar-González algorithm (CapraraSalazarGonzalez)\nDel Corso–Manzini algorithm (DelCorsoManzini)\nDel Corso–Manzini algorithm with perimeter search (DelCorsoManziniWithPS)\nSaxe–Gurari–Sudborough algorithm (SaxeGurariSudborough)\n\nThis submodule is part of the MatrixBandwidth.Minimization submodule of the MatrixBandwidth.jl package.\n\n\n\n\n\n","category":"module"},{"location":"public_api/#MatrixBandwidth.Minimization.Exact.CapraraSalazarGonzalez","page":"Public API","title":"MatrixBandwidth.Minimization.Exact.CapraraSalazarGonzalez","text":"CapraraSalazarGonzalez <: ExactSolver <: AbstractSolver\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Exact.DelCorsoManzini","page":"Public API","title":"MatrixBandwidth.Minimization.Exact.DelCorsoManzini","text":"DelCorsoManzini <: ExactSolver <: AbstractSolver\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Exact.DelCorsoManziniWithPS","page":"Public API","title":"MatrixBandwidth.Minimization.Exact.DelCorsoManziniWithPS","text":"DelCorsoManziniWithPS <: ExactSolver <: AbstractSolver\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Exact.SaxeGurariSudborough","page":"Public API","title":"MatrixBandwidth.Minimization.Exact.SaxeGurariSudborough","text":"SaxeGurariSudborough <: ExactSolver <: AbstractSolver\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Heuristic","page":"Public API","title":"MatrixBandwidth.Minimization.Heuristic","text":"MatrixBandwidth.Minimization.Heuristic\n\nHeuristic solvers for matrix bandwidth minimization.\n\nHeuristic methods are those which aim to produce near-optimal solutions in a more performant manner than exact methods. While precise bandwidth minimization is NP-complete, many heuristic algorithms (such as reverse Cuthill–McKee) run in polynomial time.\n\nHeuristic algorithms differ from metaheuristic ones in that they do not employ higher-level iterative search frameworks (e.g., stochastic techniques) to survey the global search space and escape local minima; instead, they rely on straightforward deterministic procedures to find good solutions in a single pass.\n\nThe following heuristic algorithms are currently supported:\n\nGibbs–Poole–Stockmeyer algorithm (GibbsPooleStockmeyer)\nCuthill–McKee algorithm (CuthillMcKee)\nReverse Cuthill–McKee algorithm (ReverseCuthillMcKee)\n\nThis submodule is part of the MatrixBandwidth.Minimization submodule of the MatrixBandwidth.jl package.\n\n\n\n\n\n","category":"module"},{"location":"public_api/#MatrixBandwidth.Minimization.Heuristic.CuthillMcKee","page":"Public API","title":"MatrixBandwidth.Minimization.Heuristic.CuthillMcKee","text":"CuthillMcKee <: HeuristicSolver <: AbstractSolver\n\nThe Cuthill–McKee algorithm is a heuristic method for minimizing the bandwidth of a symmetric matrix A. It considers the graph G(A) whose adjacency matrix is A (ignoring self-loops) and performs a breadth-first search of each connected component of G(A), starting from a low-degree node then visiting its neighbors in order of increasing degree. Particularly effective when A is sparse, this heuristic typically produces an ordering which induces a matrix bandwidth either equal to or very close to the true minimum [CM69, pp. 157–58].\n\nAs noted above, the input matrix must be symmetric for Cuthill–McKee to work.\n\nFields\n\nnode_selector::Function: a function that selects a node from some connected component of   the input matrix from which to start the breadth-first search. If no custom heuristic is   specified, this field defaults to pseudo_peripheral_node, which picks a node   \"farthest\" from the others in the component (not necessarily the lowest-degree node).\n\nPerformance\n\nGiven an nn input matrix A, the Cuthill–McKee algorithm runs in O(n²) time.\n\n[CG80] provide a linear-time implementation in the number of nonzero entries of A, which is still quadratic when A is dense but often much faster when dealing with sparse matrices. However, this would require that A be stored as a graph or a sparse matrix, which runs counter to our desire to provide a bandwidth minimization API for all AbstractMatrix{<:Number} types, including dense matrices. (In the future, however, we may indeed consider supporting this more performant implementation for sparse matrices.)\n\nIt was found in [Geo71, pp. 114–15] that reversing the ordering produced by Cuthill–McKee tends to induce a more optimal matrix profile (a measure of how far, on average, nonzero entries are from the diagonal). This so-called reverse Cuthill–McKee variant is preferred in almost all cases—see ReverseCuthillMcKee and the associated method of _bool_minimal_band_ordering for our implementation.\n\nExamples\n\nIn the following examples, MatrixBandwidth.random_banded_matrix is used to generate random matrices with minimum bandwidth close to k. In some cases, however, the true minimum bandwidth up to symmetric permutation may be even less than k, making it hard to verify whether Cuthill–McKee finds a truly optimal ordering or simply a near-optimal one. Nevertheless, the results are still very good in practice.\n\nCuthill–McKee finds a good ordering for a 3030 matrix whose rows and columns have been shuffled:\n\njulia> using Random\n\njulia> Random.seed!(13);\n\njulia> (n, k) = (30, 5);\n\njulia> A = random_banded_matrix(n, k);\n\njulia> perm = randperm(n);\n\njulia> A_shuffled = A[perm, perm];\n\njulia> bandwidth(A)\n5\n\njulia> bandwidth(A_shuffled) # Much larger after shuffling\n25\n\njulia> res = minimize_bandwidth(A_shuffled, Minimization.CuthillMcKee())\nResults of Bandwidth Minimization Algorithm\n * Algorithm: Cuthill–McKee\n * Approach: heuristic\n * Minimum Bandwidth: 5\n * Original Bandwidth: 25\n * Matrix Size: 30×30\n\nCuthill–McKee finds a good ordering for a structurally symmetric 183183 matrix with multiple (separate) connected components whose rows and columns have been shuffled:\n\njulia> using Random, SparseArrays\n\njulia> Random.seed!(37452);\n\njulia> (max_cc_size, max_band, p, num_ccs) = (60, 9, 0.2, 7);\n\njulia> components = Vector{SparseMatrixCSC{Float64, Int64}}(undef, num_ccs);\n\njulia> for i in 1:num_ccs # Some components may themselves be disconnected\n           cc_size = rand(1:max_cc_size);\n           cc_band = rand(0:min(max_band, cc_size - 1));\n           components[i] = sparse(random_banded_matrix(cc_size, cc_band; p=p));\n       end\n\njulia> A = blockdiag(components...); # `A` has least 7 connected components\n\njulia> perm = randperm(sum(map(cc -> size(cc, 1), components)));\n\njulia> A_shuffled = A[perm, perm];\n\njulia> res = minimize_bandwidth(A_shuffled, Minimization.CuthillMcKee());\n\njulia> A # The original matrix\n276×276 SparseMatrixCSC{Float64, Int64} with 464 stored entries:\n⎡⢾⡷⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤\n⎢⠀⠘⢻⣲⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠘⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠈⠿⡧⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠉⢯⡷⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠚⣤⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⢻⣶⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠯⡧⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠛⣤⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠛⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⣤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠱⣢⡀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⡢⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢴⣷⡀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠿⣧⡀⠀⎥\n⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢿⡷⎦\n\njulia> A_shuffled # A far-from-optimal ordering of `A`\n276×276 SparseMatrixCSC{Float64, Int64} with 464 stored entries:\n⎡⠁⢄⠀⢀⠀⠀⠀⢀⠠⠀⠀⠐⠀⠀⠀⠐⢀⡐⠀⠀⠀⢀⠀⠀⠀⠀⠐⠀⢠⠀⠀⠀⡄⠀⠀⠐⠀⠀⠂⠄⎤\n⎢⠀⢀⠱⠂⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⢨⠀⠀⠀⠀⠀⡀⠁⠠⠀⠘⠀⠀⠡⢀⠈⠀⠀⠀⠀⠀⠀⠄⠀⠁⠁⎥\n⎢⠀⠀⠀⠀⠑⢀⠀⠂⠀⠀⠀⠀⢐⠀⠀⠠⠈⠠⠀⠀⠀⠐⠀⠐⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⢢⢀⢀⠀⎥\n⎢⠀⢀⡀⠀⠠⠀⠁⠄⠀⠠⠀⠄⠀⠀⠀⠄⠀⠀⠀⠀⢀⠀⠀⢀⠀⠑⠀⠀⠐⠠⠀⠀⠠⠨⠂⠀⠀⠀⠀⠀⎥\n⎢⠀⠂⠀⠀⠀⠀⠀⡀⠱⢆⡀⠂⠀⠀⠀⠀⠀⠀⢀⢊⠀⠐⠐⠈⠀⠈⠀⢀⠄⠀⡀⠀⢁⢀⠠⠀⠃⠀⠊⠀⎥\n⎢⢀⠀⠀⠀⠀⠀⠀⠄⠠⠈⠑⠀⢀⠐⠀⠌⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡀⠀⠀⠀⢀⠉⢀⠀⠠⠈⠀⠀⣁⠁⎥\n⎢⠀⠀⠀⠀⠐⠐⠀⠀⠀⠀⢀⠐⠁⠄⠈⠀⢌⠀⠆⠠⢀⠀⠄⠐⠰⠀⠀⠀⠁⠰⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⢀⠀⠂⠒⠀⡀⠀⠄⠀⠀⡀⠄⠂⠀⠐⢄⠁⢀⠀⠀⠀⡀⠀⠀⠀⠀⡠⠀⠀⠀⠀⠀⠀⠀⠀⢈⠀⠀⠀⠁⎥\n⎢⢀⠰⠀⠀⠂⡀⠀⠀⠀⠀⠀⠈⠂⠑⠁⢀⠐⠄⠄⠂⠂⠜⠄⠀⠀⠀⡄⠀⠀⢀⠀⠠⠀⢀⠄⠀⢀⠀⠂⡂⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⡠⢐⠀⠀⠈⡁⠀⠀⠠⠁⠀⢀⠀⠀⠀⠀⡀⠀⠀⢀⠀⠈⠃⠀⠸⠈⠠⠀⠀⠀⢄⠂⎥\n⎢⠀⢀⠄⠈⢀⠀⠀⠐⢀⠀⠀⠀⠀⠐⠀⠠⣈⠄⠀⠀⠐⢀⠀⡀⠀⠀⠀⠀⠀⠀⠐⠀⠀⠊⠀⠠⠀⠐⠀⠀⎥\n⎢⠀⠀⠀⠂⢀⠀⠀⢀⡐⠀⠀⠀⢀⠁⠀⠀⠀⠁⠀⠀⠀⠠⠄⣥⠉⠈⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⡀⠀⠀⠀⎥\n⎢⠀⠀⠒⠀⠀⠀⢄⠀⡀⠀⠀⠀⠐⠂⠀⠀⠀⠀⠀⠈⠀⠀⡃⠀⠁⢀⠀⠀⢀⡀⢈⠈⠀⠀⠀⠂⠀⠠⠂⠂⎥\n⎢⠐⠀⠄⡀⠀⠀⠀⠀⠀⢀⠀⠈⠀⠀⠀⠊⠀⠉⠀⢀⠀⠀⠀⠀⠀⠀⠑⠀⠀⠀⠀⠀⢀⠀⠈⠀⠛⠃⢄⠀⎥\n⎢⠀⠒⡀⠐⠀⠀⠐⡀⠀⠁⠀⠀⢁⡀⠀⠀⠀⢀⡀⠀⠀⠀⠀⠀⠀⠰⠀⠀⠀⢄⠀⠰⠀⠠⠠⢀⠀⠀⢂⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⡄⠐⠂⠀⠀⠀⠀⡀⠉⠀⠐⠀⠀⠈⡂⠐⠀⠀⢀⡀⠀⣠⠀⠄⠠⠀⠀⡀⠀⠀⎥\n⎢⠀⠉⠀⠀⠀⠀⡀⡂⠁⢐⠀⠐⠀⠀⠀⠀⠀⢀⡒⠂⡠⠀⠀⠀⠀⠀⠀⠐⠀⡀⠀⠄⠑⠄⠀⠀⠀⠀⠀⠀⎥\n⎢⢀⠀⠀⠀⠀⡀⠈⠀⠀⠂⡀⠂⠀⠀⡀⢀⠀⠁⠀⠂⠀⡀⠀⠀⠠⠀⠂⠀⠀⢂⠀⠂⠀⠀⠁⢀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠁⠈⢒⠀⠀⠉⠀⠀⠀⠀⠀⠀⠀⠀⠐⠀⠀⢀⠀⠀⠈⠀⡀⠿⠀⠀⠀⠀⠠⠀⠀⠀⠀⠱⠆⠀⠀⎥\n⎣⠈⠄⠅⠀⠀⠐⠀⠀⠊⠀⠅⠘⠀⠀⠄⠀⠨⠠⠠⠑⠀⠀⠀⠀⠨⠀⠀⠑⠈⠐⠀⠀⠀⠀⠀⠀⠀⠀⠔⢅⎦\n\njulia> A_shuffled[res.ordering, res.ordering] # A near-optimal reordering of `A_shuffled`\n276×276 SparseMatrixCSC{Float64, Int64} with 464 stored entries:\n⎡⠱⣦⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤\n⎢⠀⠉⠻⣦⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠘⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠈⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠈⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⡦⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⡦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠺⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠚⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠁⢄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢄⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢄⠀⠀⎥\n⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⎦\n\njulia> bandwidth(A)\n7\n\njulia> bandwidth(A_shuffled) # Much larger after shuffling\n266\n\njulia> res # Even better than the original bandwidth (which was not optimal)\nResults of Bandwidth Minimization Algorithm\n * Algorithm: Cuthill–McKee\n * Approach: heuristic\n * Minimum Bandwidth: 5\n * Original Bandwidth: 266\n * Matrix Size: 276×276\n\nNotes\n\nNote that the node_selector field must be of the form (A::AbstractMatrix{Bool}) -> Integer (i.e., it must take in an boolean matrix and return an integer). If this is not the case, an ArgumentError is thrown upon construction.\n\nSee also the documentation for supertypes HeuristicSolver and AbstractSolver.\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Heuristic.GibbsPooleStockmeyer","page":"Public API","title":"MatrixBandwidth.Minimization.Heuristic.GibbsPooleStockmeyer","text":"GibbsPooleStockmeyer <: HeuristicSolver <: AbstractSolver\n\nTODO: Write here. Do we need a node selector?\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Heuristic.ReverseCuthillMcKee","page":"Public API","title":"MatrixBandwidth.Minimization.Heuristic.ReverseCuthillMcKee","text":"ReverseCuthillMcKee <: HeuristicSolver <: AbstractSolver\n\nThe reverse Cuthill–McKee algorithm is a variant of the Cuthill–McKee algorithm—a heuristic method for minimizing the bandwidth of a symmetric matrix A. Cuthill–McKee considers the graph G(A) whose adjacency matrix is A (ignoring self-loops) and performs a breadth-first search of each connected component of G(A), starting from a low-degree node then visiting its neighbors in order of increasing degree. Particularly effective when A is sparse, this heuristic typically produces an ordering which induces a matrix bandwidth either equal to or very close to the true minimum [CM69, pp. 157–58]. The reverse Cuthill–McKee algorithm simply reverses the ordering produced by application of Cuthill–McKee; it was found in [Geo71, pp. 114–15] that although the bandwidth remains the same, this tends to produce a more optimal matrix profile (a measure of how far, on average, nonzero entries are from the diagonal).\n\nAs noted above, the input matrix must be symmetric for reverse Cuthill–McKee to work.\n\nPerformance\n\nGiven an nn input matrix A, the reverse Cuthill–McKee algorithm runs in O(n²) time.\n\n[CG80] provide a linear-time implementation in the number of nonzero entries of A, which is still quadratic when A is dense but often much faster when dealing with sparse matrices. However, this would require that A be stored as a graph or a sparse matrix, which runs counter to our desire to provide a bandwidth minimization API for all AbstractMatrix{<:Number} types, including dense matrices. (In the future, however, we may indeed consider supporting this more performant implementation for sparse matrices.)\n\nFields\n\nnode_selector::Function: a function that selects a node from some connected component of   the input matrix from which to start the breadth-first search. If no custom heuristic is   specified, this field defaults to pseudo_peripheral_node, which picks a node   \"farthest\" from the others in the component (not necessarily the lowest-degree node).\n\nExamples\n\nIn the following examples, MatrixBandwidth.random_banded_matrix is used to generate random matrices with minimum bandwidth close to k. In some cases, however, the true minimum bandwidth up to symmetric permutation may be even less than k, making it hard to verify whether reverse Cuthill–McKee finds a truly optimal ordering or simply a near-optimal one. Nevertheless, the results are still very good in practice.\n\nReverse Cuthill–McKee finds a good ordering for a 3535 matrix whose rows and columns have been shuffled:\n\njulia> using Random\n\njulia> Random.seed!(87);\n\njulia> (n, k) = (35, 3);\n\njulia> A = random_banded_matrix(n, k);\n\njulia> perm = randperm(n);\n\njulia> A_shuffled = A[perm, perm];\n\njulia> bandwidth(A)\n3\n\njulia> bandwidth(A_shuffled) # Much larger after shuffling\n30\n\njulia> res = minimize_bandwidth(A_shuffled, Minimization.ReverseCuthillMcKee())\nResults of Bandwidth Minimization Algorithm\n * Algorithm: Reverse Cuthill–McKee\n * Approach: heuristic\n * Minimum Bandwidth: 3\n * Original Bandwidth: 30\n * Matrix Size: 35×35\n\nReverse Cuthill–McKee finds a good ordering for a 235235 matrix with multiple (separate) connected components whose rows and columns have been shuffled:\n\njulia> using Random, SparseArrays\n\njulia> Random.seed!(5747);\n\njulia> (max_cc_size, max_band, p, num_ccs) = (60, 9, 0.2, 8);\n\njulia> components = Vector{SparseMatrixCSC{Float64, Int64}}(undef, num_ccs);\n\njulia> for i in 1:num_ccs # Some components may themselves be disconnected\n           cc_size = rand(0:max_cc_size);\n           cc_band = rand(1:min(max_band, cc_size - 1));\n           components[i] = sparse(random_banded_matrix(cc_size, cc_band; p=p));\n       end\n\njulia> A = blockdiag(components...); # `A` has least 8 connected components\n\njulia> perm = randperm(sum(map(cc -> size(cc, 1), components)));\n\njulia> A_shuffled = A[perm, perm];\n\njulia> res = minimize_bandwidth(A_shuffled, Minimization.ReverseCuthillMcKee());\n\njulia> A # The original matrix\n235×235 SparseMatrixCSC{Float64, Int64} with 445 stored entries:\n⎡⢾⣳⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤\n⎢⠀⠘⢿⡷⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠈⠏⣥⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠉⢴⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠙⠻⢂⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⣮⣿⣢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠚⢿⡳⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⢰⣶⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠾⡧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⣢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⡠⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⠖⣀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢏⡱⣄⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢮⣷⣄⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢻⣲⣄⠀⎥\n⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢻⢖⎦\n\njulia> A_shuffled # A far-from-optimal ordering of `A`\n235×235 SparseMatrixCSC{Float64, Int64} with 445 stored entries:\n⎡⠑⠄⠀⠀⠀⠀⠀⢀⢀⠀⠄⠀⠀⠀⠀⠀⠀⠀⠀⠄⠀⡐⠀⠐⠀⠂⠀⠀⠀⠀⠀⠀⡂⠀⢀⠄⠁⠠⠐⠀⎤\n⎢⠀⠀⠀⢄⡀⠀⢁⠀⠀⠈⠀⠁⠀⠀⠀⢀⠁⠄⠈⠀⠀⠀⠀⠐⠀⠀⠀⠀⠀⠈⠀⠂⠠⠀⠀⠀⠀⠀⡀⠐⎥\n⎢⠀⠀⠀⠈⠁⢀⠀⠑⠀⢀⠁⢀⠀⠈⠀⠘⠌⠀⢀⠀⠄⠀⠂⡄⠄⠁⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⣂⠀⠀⠀⎥\n⎢⠀⢀⠁⠐⢄⠀⠠⢆⠀⠀⠀⠀⠀⠀⠀⢀⠠⡀⠀⠀⠠⠀⠀⠀⠐⠀⠀⡀⠀⢀⠀⠀⠀⠈⠀⡀⠀⠀⠘⠀⎥\n⎢⠀⠐⡀⠀⠀⢀⠀⠀⢀⢔⠈⢀⠀⠀⣐⠀⠀⠀⢀⠀⠀⠀⠀⠀⠐⠀⠄⢠⠀⠀⠀⠀⠀⠀⠀⡀⠀⠈⠣⡀⎥\n⎢⠀⠁⠄⠀⠁⢀⠀⠀⠂⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⠀⡀⠀⠀⡐⠐⠀⡀⠀⠀⠂⠀⠀⠀⢀⠀⠀⠄⠀⎥\n⎢⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⠀⠀⠑⠀⠀⠀⠀⠀⠀⠀⡠⠀⡀⠀⠀⠄⠀⠀⠠⠀⠀⠠⠀⠀⠀⠀⡠⠄⠀⠄⎥\n⎢⠀⠀⠀⢀⣀⠀⠀⢀⠐⠘⠀⠀⠀⠀⠕⢅⠀⠀⠀⠀⠀⠀⠀⡀⠀⠀⢀⠐⡀⠀⠈⠀⠂⠀⠀⢀⠀⠃⠀⠄⎥\n⎢⠀⠀⠁⠄⠂⠁⠀⠢⠀⠀⠀⠀⠀⠀⠀⠀⠛⢄⢸⠘⠀⠀⠀⠀⠄⠈⠁⠀⠀⠨⠀⠀⢀⠀⠀⠨⠀⠀⠈⠀⎥\n⎢⠀⠄⠂⠀⠀⠐⠀⠀⠀⠐⠀⠀⠀⠀⠀⠀⣒⠒⠁⠀⢠⠀⠀⠀⠐⠀⠀⠀⢁⠀⠐⠈⠀⠀⠂⠀⠂⡀⠀⠀⎥\n⎢⢀⠠⠀⠀⠀⠁⠀⠂⠀⠀⠀⠂⠀⠊⠀⠀⠀⠀⠀⠒⠑⠀⠀⠀⠀⠂⢀⠁⡂⠀⠀⢀⠀⠀⠀⠀⠁⠂⡊⠂⎥\n⎢⢀⠀⢀⠀⠈⠤⠀⠀⠀⠀⠀⠈⠀⠈⠀⠠⠀⠀⠀⠀⠀⠀⠁⢀⠅⠀⢀⠀⠀⠀⢀⠀⡁⠀⠀⠀⠀⠠⠀⠀⎥\n⎢⠠⠀⠀⠀⠄⠁⠐⠀⠐⠀⢀⠠⠀⠄⠀⠀⡀⠁⠐⠀⠠⠀⠁⠁⠁⠀⢀⠄⠀⠉⠀⠃⠀⠀⠀⠀⠠⢠⠂⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠠⠀⣁⠐⠀⠀⠀⢀⠐⠁⠀⠀⠀⠄⠐⠀⠐⠀⠔⡑⠌⠀⠀⠀⠀⠢⢉⠀⠀⠄⠀⠀⠄⎥\n⎢⠀⠀⡀⠀⠂⠀⠀⢀⠀⠀⠀⠈⠀⠂⠀⠈⡀⡀⠁⠐⠈⠈⠀⠀⡄⠀⠀⠀⠄⠅⠀⡀⠀⠀⠀⠠⠀⠰⠀⠂⎥\n⎢⠀⠀⠠⠀⠀⠀⠀⠀⠀⠀⠠⠀⠀⡀⠂⠀⠀⠀⡐⠀⠀⢀⠀⠐⠤⠀⠀⠀⠀⠠⠀⢀⠀⠀⠀⠀⠀⠀⠒⢀⎥\n⎢⠈⠈⠀⠂⠀⠀⡀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⠐⠀⠀⠀⠀⠁⠈⠀⠀⡌⢂⠀⠀⠀⠀⠀⠄⠈⠀⠀⡀⠀⠀⎥\n⎢⠀⠔⠀⠀⠀⠀⠀⠠⠀⠠⠀⢀⠀⠀⠀⢀⡀⡀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡀⠀⠀⠂⠀⠡⠂⠀⠀⡠⠀⎥\n⎢⠁⡀⠀⠀⠈⠘⠀⠀⡀⠀⠀⠀⠀⠎⠤⠀⠀⠀⠈⠠⠡⠀⠀⡀⠀⣂⠀⠁⢀⡀⠀⠀⠀⠠⠀⠀⠰⠆⠌⠀⎥\n⎣⠐⠀⢀⠈⠀⠀⠒⠀⠉⠢⠀⠁⠀⠄⠀⠄⠂⠀⠀⠀⠪⠈⠀⠀⠈⠀⠀⠄⠠⠀⠘⢀⠀⠀⠀⠊⠂⠁⠐⢀⎦\n\njulia> A_shuffled[res.ordering, res.ordering] # A near-optimal reordering of `A_shuffled`\n235×235 SparseMatrixCSC{Float64, Int64} with 445 stored entries:\n⎡⠁⠄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤\n⎢⠀⠀⠁⢄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠈⠀⠄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠁⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠑⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠁⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢛⢔⢤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠳⣿⣿⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠚⣤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠡⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠫⣦⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠛⢿⣷⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠯⣧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠯⣧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠺⢆⡄⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⢻⣲⣄⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢻⣶⡀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣢⡀⠀⎥\n⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠱⣦⎦\n\njulia> bandwidth(A)\n9\n\njulia> bandwidth(A_shuffled) # Much larger after shuffling\n226\n\njulia> res # Gets very close to the original bandwidth\nResults of Bandwidth Minimization Algorithm\n * Algorithm: Reverse Cuthill–McKee\n * Approach: heuristic\n * Minimum Bandwidth: 9\n * Original Bandwidth: 226\n * Matrix Size: 235×235\n\nNotes\n\nNote that the node_selector field must be of the form (A::AbstractMatrix{Bool}) -> Integer (i.e., it must take in an boolean matrix and return an integer). If this is not the case, an ArgumentError is thrown upon construction.\n\nSee also the documentation for supertypes HeuristicSolver and AbstractSolver, as well as CuthillMcKee for the original non-reversed algorithm. (Indeed, the reverse Cuthill–McKee method of _bool_minimal_band_ordering is merely a wrapper around the Cuthill–McKee method.)\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Metaheuristic","page":"Public API","title":"MatrixBandwidth.Minimization.Metaheuristic","text":"MatrixBandwidth.Minimization.Metaheuristic\n\nMetaheuristic solvers for matrix bandwidth minimization.\n\nMetaheuristic methods are those which [TODO: Write here]\n\nThe following metaheuristic algorithms are currently supported:\n\nGreedy randomized adaptive search procedure (GRASP) (GRASP)\nSimulated annealing (SimulatedAnnealing)\nGenetic algorithm (GeneticAlgorithm)\n\nThis submodule is part of the MatrixBandwidth.Minimization submodule of the MatrixBandwidth.jl package.\n\n\n\n\n\n","category":"module"},{"location":"public_api/#MatrixBandwidth.Minimization.Metaheuristic.GRASP","page":"Public API","title":"MatrixBandwidth.Minimization.Metaheuristic.GRASP","text":"GRASP <: MetaheuristicSolver <: AbstractSolver\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Metaheuristic.GeneticAlgorithm","page":"Public API","title":"MatrixBandwidth.Minimization.Metaheuristic.GeneticAlgorithm","text":"GeneticAlgorithm <: MetaheuristicSolver <: AbstractSolver\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Minimization.Metaheuristic.SimulatedAnnealing","page":"Public API","title":"MatrixBandwidth.Minimization.Metaheuristic.SimulatedAnnealing","text":"SimulatedAnnealing <: MetaheuristicSolver <: AbstractSolver\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Recognition","page":"Public API","title":"MatrixBandwidth.Recognition","text":"MatrixBandwidth.Recognition\n\nAlgorithms for matrix bandwidth recognition in Julia.\n\nThe bandwidth of a square matrix A is the minimum non-negative integer k  ℕ such that Ai j = 0 whenever i - j  k. Equivalently, A has bandwidth at most k if all entries above the k-th superdiagonal and below the k-th subdiagonal are zero, and A has bandwidth at least k if there exists any nonzero entry in the k-th superdiagonal or subdiagonal.\n\nThe matrix bandwidth recognition problem entails determining whether there exists a permutation matrix P such that the bandwidth of PAPᵀ is at most some fixed non-negative integer k  ℕ—an optimal permutation that fully minimizes the bandwidth of A is not required. Unlike the NP-hard minimization problem, this is decidable in O(nᵏ) time, where n is the order of A.\n\nThe following algorithms are currently supported:\n\nCaprara–Salazar-González algorithm (CapraraSalazarGonzalez)\nDel Corso–Manzini algorithm (DelCorsoManzini)\nDel Corso–Manzini algorithm with perimeter search (DelCorsoManziniWithPS)\nSaxe–Gurari–Sudborough algorithm (SaxeGurariSudborough)\n\nThis submodule is part of the MatrixBandwidth.jl package.\n\n\n\n\n\n","category":"module"},{"location":"public_api/#MatrixBandwidth.Recognition.CapraraSalazarGonzalez","page":"Public API","title":"MatrixBandwidth.Recognition.CapraraSalazarGonzalez","text":"CapraraSalazarGonzalez <: AbstractDecider\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Recognition.DelCorsoManzini","page":"Public API","title":"MatrixBandwidth.Recognition.DelCorsoManzini","text":"DelCorsoManzini <: AbstractDecider\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Recognition.DelCorsoManziniWithPS","page":"Public API","title":"MatrixBandwidth.Recognition.DelCorsoManziniWithPS","text":"DelCorsoManziniWithPS <: AbstractDecider\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Recognition.RecognitionResult","page":"Public API","title":"MatrixBandwidth.Recognition.RecognitionResult","text":"RecognitionResult{A,M,O} <: AbstractResult\n\nOutput struct for matrix bandwidth recognition results.\n\nFields\n\nalgorithm::A<:AbstractDecider: the decider used to test the bandwidth.\nmatrix::M<:AbstractMatrix{<:Number}: the original matrix whose bandwidth is tested.\nordering::O<:Union{Nothing,Vector{Int}}: an ordering of the rows and columns of matrix   inducing a bandwidth at most k, if such an ordering exists; otherwise, nothing.\nk::Int: the threshold bandwidth against which to test.\nhas_bandwidth_k_ordering::Bool: whether the matrix has an ordering inducing a bandwidth   at most k. (This is true if and only if ordering is not nothing.)\n\nConstructors\n\nRecognitionResult(decider, matrix, ordering, k): constructs a new RecognitionResult   instance with the given fields. The has_bandwidth_k_ordering field is automatically   determined based on whether ordering is nothing or a Vector{Int}.\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Recognition.SaxeGurariSudborough","page":"Public API","title":"MatrixBandwidth.Recognition.SaxeGurariSudborough","text":"SaxeGurariSudborough <: AbstractDecider\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"public_api/#MatrixBandwidth.Recognition.has_bandwidth_k_ordering","page":"Public API","title":"MatrixBandwidth.Recognition.has_bandwidth_k_ordering","text":"has_bandwidth_k_ordering(A, k, decider=CapraraSalazarGonzalez()) -> RecognitionResult\n\nDetermine whether A has bandwidth at most k using the algorithm defined by decider.\n\nThe bandwidth of a square matrix A is the minimum non-negative integer k  ℕ such that Ai j = 0 whenever i - j  k. Equivalently, A has bandwidth at most k if all entries above the k-th superdiagonal and below the k-th subdiagonal are zero, and A has bandwidth at least k if there exists any nonzero entry in the k-th superdiagonal or subdiagonal.\n\nThis function [TODO: Write here]\n\nArguments\n\nA::AbstractMatrix{<:Number}: the (square) matrix whose bandwidth is tested.\nk::Int: the threshold bandwidth against which to test.\ndecider::AbstractDecider: the matrix bandwidth recognition algorithm to use; defaults to   CapraraSalazarGonzalez. (See the Recognition module documentation   for a full list of supported deciders.)\n\nReturns\n\n::RecognitionResult: TODO: Write here\n\nExamples\n\n[TODO: Add here once more deciders are implemented]\n\nNotes\n\nSome texts define matrix bandwidth to be the minimum non-negative integer k such that Ai j = 0 whenever i - j  k instead, particularly in more mathematically-minded communities. Effectively, this definition treats diagonal matrices as bandwidth 1, tridiagonal matrices as bandwidth 2, and so on. Our definition, on the other hand, is more common in computer science contexts, treating diagonal matrices as bandwidth 0 and tridiagonal matrices as bandwidth 1. (Both definitions, however, agree that the bandwidth of an empty matrix is simply 0.)\n\n\n\n\n\n","category":"function"},{"location":"public_api/#References","page":"Public API","title":"References","text":"","category":"section"},{"location":"public_api/","page":"Public API","title":"Public API","text":"A. Caprara and J.-J. Salazar-González. Laying Out Sparse Graphs with Provably Minimum Bandwidth. INFORMS Journal on Computing 17, 356–73 (2005).\n\n\n\nW. M. Chan and A. George. A linear time implementation of the reverse Cuthill-McKee algorithm. BIT Numerical Mathematics 20, 8–14 (1980).\n\n\n\nE. Cuthill and J. McKee. Reducing the bandwidth of sparse symmetric matrices. In: Proceedings of the 24th National Conference of the ACM (Brandon Systems Press, 1969); pp. 157–72.\n\n\n\nJ. A. George. Computer Implementation of the Finite Element Method. Ph.D. Thesis, Department of Computer Science, Stanford University (1971).\n\n\n\n","category":"page"},{"location":"private_api/#MatrixBandwidth.jl-–-Private-API","page":"Private API","title":"MatrixBandwidth.jl – Private API","text":"","category":"section"},{"location":"private_api/","page":"Private API","title":"Private API","text":"Documentation for MatrixBandwidth's private API.","category":"page"},{"location":"private_api/","page":"Private API","title":"Private API","text":"note: Note\nThe following documentation covers only the private API of the package. For public details, see the public API documentation.","category":"page"},{"location":"private_api/#MatrixBandwidth.AbstractAlgorithm","page":"Private API","title":"MatrixBandwidth.AbstractAlgorithm","text":"AbstractAlgorithm\n\nAbstract base type for all matrix bandwidth minimization and recognition algorithms.\n\nInterface\n\nConcrete subtypes of AbstractAlgorithm must implement the following methods:\n\nBase.summary(::T) where {T<:AbstractAlgorithm}: returns a String indicating the name   of the algorithm (e.g., \"Reverse Cuthill–McKee\").\n_requires_symmetry(::T) where {T<:AbstractAlgorithm}: returns a Bool indicating   whether the algorithm requires the input matrix to be structurally symmetric.\n\nDirect subtypes of AbstractAlgorithm must implement the following method:\n\n_problem(::T) where {T<:AbstractAlgorithm}: returns a Symbol indicating the   matrix bandwidth problem tackled by the algorithm (e.g., :minimization).\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.AbstractResult","page":"Private API","title":"MatrixBandwidth.AbstractResult","text":"AbstractResult\n\nAbstract base type for all matrix bandwidth problem results.\n\nInterface\n\nConcrete subtypes of AbstractResult must implement parametric types\n\nA<:AbstractAlgorithm;\nM<:AbstractMatrix{<:Number}; and\nO<:Union{Nothing,Vector{Int}},\n\nalongside the following fields:\n\nalgorithm::A: the algorithm used to investigate the bandwidth.\nmatrix::M: the matrix whose bandwidth is investigated.\nordering::O: the corresponding ordering of the rows and columns, if a relevant one is   found; otherwise, nothing.\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.NotImplementedError","page":"Private API","title":"MatrixBandwidth.NotImplementedError","text":"NotImplementedError{Nothing}(f, subtype, abstracttype)\nNotImplementedError{Symbol}(f, arg, subtype, abstracttype)\n\nAn exception indicating that a function lacks dispatch to handle a specific argument type.\n\nSemantically, this differs from MethodError in that it connotes a developer-side failure to implement a method rather than erroneous user input. Throughout this package, it is often used to warn when an existing function with multiple dispatch on some abstract type is called on a newly created subtype for which no method has been defined.\n\nFields\n\nf::Function: the function called.\narg::Symbol: the name of the argument with the unsupported type, if the function has   multiple arguments. If the function has only one argument, this field should be set to   nothing.\nsubtype::Type: the type of the argument. May be the actual concrete type or some   intermediate supertype. (For instance, if the relevant input has concrete type A with   hierarchy A <: B <: C and the abstracttype field is C, then both A and B are   perfectly valid choices for subtype.)\nabstracttype::Type: the abstract type under which the argument is meant to fall.\n\nConstructors\n\nNotImplementedError(::Function, ::Type, ::Type): constructs a new NotImplementedError   instance for a single-argument function. Throws an error if the second type is not   abstract or the first type is not a subtype of the second.\nNotImplementedError(::Function, ::Symbol, ::Type, ::Type): constructs a new   NotImplementedError instance for a multi-argument function. Throws an error if the   second type is not abstract or the first type is not a subtype of the second.\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.RectangularMatrixError","page":"Private API","title":"MatrixBandwidth.RectangularMatrixError","text":"RectangularMatrixError(A)\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.StructuralAsymmetryError","page":"Private API","title":"MatrixBandwidth.StructuralAsymmetryError","text":"StructuralAsymmetryError(A, algorithm)\n\nTODO: Write here. Cite [RS06].\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.Minimization.AbstractSolver","page":"Private API","title":"MatrixBandwidth.Minimization.AbstractSolver","text":"AbstractSolver <: AbstractAlgorithm\n\nAbstract base type for all matrix bandwidth minimization solvers.\n\nInterface\n\nAs per the interface of supertype AbstractAlgorithm, concrete subtypes of AbstractSolver must implement the following methods:\n\nBase.summary(::T) where {T<:AbstractSolver}: returns a String indicating the name   of the solver (e.g., \"Reverse Cuthill–McKee\").\n_requires_symmetry(::T) where {T<:AbstractSolver}: returns a Bool indicating   whether the solver requires the input matrix to be structurally symmetric.\n\nDirect subtypes of AbstractSolver must implement the following method:\n\n_approach(::T) where {T<:AbstractSolver}: returns a Symbol indicating the   category of solver (e.g., :heuristic).\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.Minimization.Exact.ExactSolver","page":"Private API","title":"MatrixBandwidth.Minimization.Exact.ExactSolver","text":"Exact <: AbstractSolver <: AbstractAlgorithm\n\nAbstract type for all exact matrix bandwidth minimization solvers.\n\nExact methods are those which guarantee an optimal ordering producing the true minimum bandwidth of a matrix. Since bandwidth minimization is an NP-complete problem, existing exact algorithms are, at best, exponential in time complexity—much worse than many polynomial-time heuristic approaches (e.g., reverse Cuthill–McKee). Such methods, therefore, are not feasible for large matrices, but they remain useful when precise solutions are required for small-to-medium-sized inputs (say, up to 100100).\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.Minimization.Heuristic.HeuristicSolver","page":"Private API","title":"MatrixBandwidth.Minimization.Heuristic.HeuristicSolver","text":"HeuristicSolver <: AbstractSolver <: AbstractAlgorithm\n\nAbstract type for all heuristic matrix bandwidth minimization solvers.\n\nHeuristic methods are those which aim to produce near-optimal solutions in a more performant manner than exact methods. While precise bandwidth minimization is NP-complete, many heuristic algorithms (such as reverse Cuthill–McKee) run in polynomial time.\n\nHeuristic algorithms differ from metaheuristic ones in that they do not employ higher-level iterative search frameworks (e.g., stochastic techniques) to survey the global search space and escape local minima; instead, they rely on straightforward deterministic procedures to find good solutions in a single pass.\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.Minimization.Heuristic.pseudo_peripheral_node-Tuple{AbstractMatrix{Bool}}","page":"Private API","title":"MatrixBandwidth.Minimization.Heuristic.pseudo_peripheral_node","text":"pseudo_peripheral_node(A::AbstractMatrix{Bool}) -> Int\n\nSelect a pseudo-peripheral node from the connected graph represented by A.\n\nThis function acts as a node selector for the Cuthill–McKee and Reverse Cuthill–McKee algorithms, heuristically choosing the node \"farthest\" from the others in the graph. It is assumed that A is the adjacency matrix of some connected, undirected graph; otherwise, undefined behavior may arise.\n\nArguments\n\nA::AbstractMatrix{Bool}: the adjacency matrix of some connected, undirected graph. In   practice, this semantically represents the connected component of some larger graph.\n\nReturns\n\nInt: the index of the pseudo-peripheral node selected from the graph.\n\nNotes\n\nThis function takes heavy inspiration from the implementation in [Net25], which accepts a graph object as input and leverages several pre-existing functions in the networkx library. We herein repurpose the logic to work directly on adjacency matrices, avoiding reallocation overhead and an unnecessary dependency on Graphs.jl.\n\n\n\n\n\n","category":"method"},{"location":"private_api/#MatrixBandwidth.Minimization.Metaheuristic.MetaheuristicSolver","page":"Private API","title":"MatrixBandwidth.Minimization.Metaheuristic.MetaheuristicSolver","text":"MetaheuristicSolver <: AbstractSolver <: AbstractAlgorithm\n\nTODO: Write here\n\n\n\n\n\n","category":"type"},{"location":"private_api/#MatrixBandwidth.Recognition.AbstractDecider","page":"Private API","title":"MatrixBandwidth.Recognition.AbstractDecider","text":"AbstractDecider <: AbstractAlgorithm\n\nAbstract base type for all matrix bandwidth recognition deciders.\n\nInterface\n\nAs per the interface of supertype AbstractAlgorithm, concrete subtypes of AbstractDecider must implement the following methods:\n\nBase.summary(::T) where {T<:AbstractDecider}: returns a String indicating the name   of the decider (e.g., \"Caprara–Salazar-González\").\n_requires_symmetry(::T) where {T<:AbstractDecider}: returns a Bool indicating   whether the decider requires the input matrix to be structurally symmetric.\n\n\n\n\n\n","category":"type"},{"location":"private_api/#References","page":"Private API","title":"References","text":"","category":"section"},{"location":"private_api/","page":"Private API","title":"Private API","text":"J. K. Reid and J. A. Scott. Reducing the Total Bandwidth of a Sparse Unsymmetric Matrix. SIAM Journal on Matrix Analysis and Applications 28, 805–21 (2006).\n\n\n\nNetworkX Developers. Source code for networkx.utils.rcm. NetworkX v3.5 documentation (2025). Accessed: 2025-06-11.\n\n\n\n","category":"page"},{"location":"","page":"Home","title":"Home","text":"<table>\n  <tr>\n    <td>Metadata</td>\n    <td>\n      <img src=\"https://img.shields.io/badge/version-v0.1.0--dev-pink.svg\" alt=\"Version\">\n      <a href=\"https://opensource.org/licenses/MIT\"><img src=\"https://img.shields.io/badge/License-MIT-A31F34.svg\" alt=\"License: MIT\"></a>\n      <a href=\"https://github.com/JuliaDiff/BlueStyle\"><img src=\"https://img.shields.io/badge/code%20style-blue-4495d1.svg\" alt=\"Code Style: Blue\"></a>\n    </td>\n  </tr>\n  <tr>\n    <td>Documentation</td>\n    <td>\n      <a href=\"https://luis-varona.github.io/MatrixBandwidth.jl/stable/\"><img src=\"https://img.shields.io/badge/docs-stable-darkgreen.svg\" alt=\"Documentation of latest stable version\"></a>\n      <a href=\"https://luis-varona.github.io/MatrixBandwidth.jl/dev/\"><img src=\"https://img.shields.io/badge/docs-dev-rebeccapurple.svg\" alt=\"Documentation of dev version\"></a>\n    </td>\n  </tr>\n  <tr>\n    <td>Continuous integration</td>\n    <td>\n      <a href=\"https://github.com/Luis-Varona/MatrixBandwidth.jl/actions?query=workflow%3ACI+branch%3Amain\"><img src=\"https://github.com/Luis-Varona/MatrixBandwidth.jl/actions/workflows/CI.yml/badge.svg\" alt=\"GitHub Workflow Status\"></a>\n    </td>\n  </tr>\n  <tr>\n    <td>Code coverage</td>\n    <td>\n      <a href=\"https://codecov.io/gh/Luis-Varona/MatrixBandwidth.jl\"><img src=\"https://codecov.io/gh/Luis-Varona/MatrixBandwidth.jl/branch/main/graph/badge.svg\" alt=\"Test coverage from codecov\"></a>\n    </td>\n    </tr>\n    <tr>\n      <td>Static analysis with</td>\n      <td>\n        <a href=\"https://github.com/JuliaTesting/Aqua.jl\"><img src=\"https://raw.githubusercontent.com/JuliaTesting/Aqua.jl/master/badge.svg\" alt=\"Aqua QA\"></a>\n        <a href=\"https://github.com/aviatesk/JET.jl\"><img src=\"https://img.shields.io/badge/%E2%9C%88%20tested%20with-JET.jl%EF%B8%8F-9cf.svg\" alt=\"JET static analysis\"></a>\n      </td>\n    </tr>\n</table>","category":"page"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"MatrixBandwidth.jl offers several algorithms for matrix bandwidth minimization and matrix bandwidth recognition.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The bandwidth of a square matrix A is the minimum non-negative integer k in mathbbN such that A_ij = 0 whenever i - j  k. Equivalently, A has bandwidth at most k if all entries above the k^textth superdiagonal and below the k^textth subdiagonal are zero, and A has bandwidth at least k if there exists any nonzero entry in the k^textth superdiagonal or subdiagonal.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The matrix bandwidth minimization problem involves finding a permutation matrix P such that the bandwidth of PAP^mathsfT is minimized; this is known to be NP-complete. Several heuristic algorithms (such as reverse Cuthill–McKee) run in polynomial time while still producing near-optimal orderings in practice, but exact methods (like MB-PS) are exponential in time complexity and thus are only feasible for relatively small matrices.","category":"page"},{"location":"","page":"Home","title":"Home","text":"On the other hand, the matrix bandwidth recognition problem entails determining whether there exists a permutation matrix P such that the bandwidth of PAP^mathsfT is at most some fixed integer non-negative integer k in mathbbN—an optimal permutation that fully minimizes the bandwidth of A is not required. Unlike the NP-hard minimization problem, this is decidable in O(n^k) time, where n is the order of A.","category":"page"},{"location":"#Algorithms","page":"Home","title":"Algorithms","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The following algorithms are currently supported:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Minimization\nExact\nCaprara–Salazar-González algorithm\nDel Corso–Manzini algorithm\nDel Corso–Manzini algorithm with perimeter search\nSaxe–Gurari–Sudborough algorithm\nHeuristic\nGibbs–Poole–Stockmeyer algorithm\nCuthill–McKee algorithm\nReverse Cuthill–McKee algorithm\nMetaheuristic\nGreedy randomized adaptive search procedure (GRASP)\nSimulated annealing\nGenetic algorithm\nRecognition\nCaprara–Salazar-González algorithm\nDel Corso–Manzini algorithm\nDel Corso–Manzini algorithm with perimeter search\nSaxe–Gurari–Sudborough algorithm","category":"page"},{"location":"","page":"Home","title":"Home","text":"(As we remain in the early stages of development, some of these may not yet be fully implemented and/or tested.)","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The only prerequisite is a working Julia installation (v1.10 or later). First, enter Pkg mode by typing ] in the Julia REPL, then run the following command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/Luis-Varona/MatrixBandwidth.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"When MatrixBandwidth.jl is finally added to the official Julia registry, you will be able to install it more easily with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add MatrixBandwidth","category":"page"},{"location":"#Citing","page":"Home","title":"Citing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"I encourage you to cite this work if you have found any of the algorithms herein useful for your research. Starring the MatrixBandwidth.jl repository on GitHub is also appreciated.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The latest citation information may be found in the CITATION.bib file within the repository.","category":"page"},{"location":"#Project-status","page":"Home","title":"Project status","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"I aim to release the first stable version of MatrixBandwidth.jl in mid-July 2025. The current version is a work-in-progress, with much of the API still under development.","category":"page"},{"location":"#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
