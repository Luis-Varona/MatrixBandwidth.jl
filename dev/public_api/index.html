<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Public API · MatrixBandwidth.jl</title><meta name="title" content="Public API · MatrixBandwidth.jl"/><meta property="og:title" content="Public API · MatrixBandwidth.jl"/><meta property="twitter:title" content="Public API · MatrixBandwidth.jl"/><meta name="description" content="Documentation for MatrixBandwidth.jl."/><meta property="og:description" content="Documentation for MatrixBandwidth.jl."/><meta property="twitter:description" content="Documentation for MatrixBandwidth.jl."/><meta property="og:url" content="https://Luis-Varona.github.io/MatrixBandwidth.jl/public_api/"/><meta property="twitter:url" content="https://Luis-Varona.github.io/MatrixBandwidth.jl/public_api/"/><link rel="canonical" href="https://Luis-Varona.github.io/MatrixBandwidth.jl/public_api/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MatrixBandwidth.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Public API</a><ul class="internal"><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../private_api/">Private API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Public API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Public API</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Luis-Varona/MatrixBandwidth.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/main/docs/src/public_api.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="MatrixBandwidth.jl-–-Public-API"><a class="docs-heading-anchor" href="#MatrixBandwidth.jl-–-Public-API">MatrixBandwidth.jl – Public API</a><a id="MatrixBandwidth.jl-–-Public-API-1"></a><a class="docs-heading-anchor-permalink" href="#MatrixBandwidth.jl-–-Public-API" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/Luis-Varona/MatrixBandwidth.jl">MatrixBandwidth</a>&#39;s public API.</p><div class="admonition is-info" id="Note-d315dd05c58bb28f"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-d315dd05c58bb28f" title="Permalink"></a></header><div class="admonition-body"><p>The following documentation covers only the public API of the package. For internal details, see the <a href="../private_api/">private API documentation</a>.</p></div></div><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.MatrixBandwidth" href="#MatrixBandwidth.MatrixBandwidth"><code>MatrixBandwidth.MatrixBandwidth</code></a> — <span class="docstring-category">Module</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MatrixBandwidth</code></pre><p>Exact, heuristic, and metaheuristic algorithms for matrix bandwidth minimization in Julia.</p><p>The <em>bandwidth</em> of a square matrix <span>$A$</span> is the minimum non-negative integer <span>$k ∈ ℕ$</span> such that <span>$A[i, j] = 0$</span> whenever <span>$|i - j| &gt; k$</span>. Equivalently, <span>$A$</span> has bandwidth <strong>at most</strong> <span>$k$</span> if all entries above the <span>$k$</span>-th superdiagonal and below the <span>$k$</span>-th subdiagonal are zero, and <span>$A$</span> has bandwidth <strong>at least</strong> <span>$k$</span> if there exists any nonzero entry in the <span>$k$</span>-th superdiagonal or subdiagonal.</p><p><em>Matrix bandwidth minimization</em> is the problem of finding a permutation matrix <span>$P$</span> so that the bandwidth of <span>$PAPᵀ$</span> is minimized; this is known to be NP-complete. Several heuristic algorithms (such as reverse Cuthill–McKee) run in polynomial time while still producing near-optimal orderings in practice, but exact methods (like MB-PS) are exponential in time complexity and thus only feasible for relatively small matrices.</p><p>The following algorithms are currently supported:</p><ul><li><strong>Exact</strong><ul><li><a href="#MatrixBandwidth.Exact.MBID"><code>MBID</code></a>: Minimum bandwidth by iterative deepening (MB-ID)</li><li><a href="#MatrixBandwidth.Exact.MBPS"><code>MBPS</code></a>: Minimum bandwidth by perimeter search (MB-PS)</li></ul></li><li><strong>Heuristic</strong><ul><li><a href="#MatrixBandwidth.Heuristic.CuthillMcKee"><code>CuthillMcKee</code></a>: Cuthill–McKee algorithm</li><li><a href="#MatrixBandwidth.Heuristic.ReverseCuthillMcKee"><code>ReverseCuthillMcKee</code></a>: Reverse Cuthill–McKee algorithm</li></ul></li><li><strong>Metaheuristic</strong><ul><li><a href="#MatrixBandwidth.Metaheuristic.SimulatedAnnealing"><code>SimulatedAnnealing</code></a>: Simulated annealing</li><li><a href="#MatrixBandwidth.Metaheuristic.GeneticAlgorithm"><code>GeneticAlgorithm</code></a>: Genetic algorithm</li><li><a href="#MatrixBandwidth.Metaheuristic.GRASP"><code>GRASP</code></a>: Greedy randomized adaptive search procedure (GRASP)</li></ul></li></ul><p><a href="https://Luis-Varona.github.io/MatrixBandwidth.jl/dev/">Full documentation</a> is available for the latest development version of this package.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/MatrixBandwidth.jl#L7-L38">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.BandwidthResult" href="#MatrixBandwidth.BandwidthResult"><code>MatrixBandwidth.BandwidthResult</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BandwidthResult</code></pre><p>Output struct for matrix bandwidth minimization results.</p><p><strong>Fields</strong></p><ul><li><code>matrix::M</code>: the original matrix whose bandwidth is minimized.</li><li><code>bandwidth::Int</code>: the minimized bandwidth of the matrix.</li><li><code>ordering::Vector{Int}</code>: the (near-)optimal ordering of the rows and columns.</li><li><code>solver::S</code>: the algorithm used to minimize the bandwidth.</li><li><code>approach::Symbol</code>: the approach used by the solver. (Should be one of <code>:exact</code>,   <code>:heuristic</code>, and <code>:metaheuristic</code>.)</li></ul><p><strong>Constructors</strong></p><ul><li><code>BandwidthResult(matrix, bandwidth, ordering, solver)</code>: constructs a new <code>BandwidthResult</code>   instance with the given fields. The <code>approach</code> field is automatically determined based   on the solver type.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/types.jl#L28-L45">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.bandwidth-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T&lt;:Number" href="#MatrixBandwidth.bandwidth-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T&lt;:Number"><code>MatrixBandwidth.bandwidth</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">bandwidth(A) -&gt; Int</code></pre><p>Compute the bandwidth of <code>A</code> without any permutations.</p><p>The <em>bandwidth</em> of a square matrix <span>$A$</span> is the minimum non-negative integer <span>$k ∈ ℕ$</span> such that <span>$A[i, j] = 0$</span> whenever <span>$|i - j| &gt; k$</span>. Equivalently, <span>$A$</span> has bandwidth <strong>at most</strong> <span>$k$</span> if all entries above the <span>$k$</span>-th superdiagonal and below the <span>$k$</span>-th subdiagonal are zero, and <span>$A$</span> has bandwidth <strong>at least</strong> <span>$k$</span> if there exists any nonzero entry in the <span>$k$</span>-th superdiagonal or subdiagonal.</p><p>In contrast to <a href="#MatrixBandwidth.minimize_bandwidth-Union{Tuple{AbstractMatrix{T}}, Tuple{T}, Tuple{AbstractMatrix{T}, MatrixBandwidth.AbstractSolver}} where T&lt;:Number"><code>minimize_bandwidth</code></a>, this function does not attempt to minimize the bandwidth of <code>A</code> by permuting its rows and columns—it simply computes its bandwidth as is.</p><p><strong>Arguments</strong></p><ul><li><code>A::AbstractMatrix{T}</code>: the (square) matrix whose bandwidth is to be computed.</li></ul><p><strong>Returns</strong></p><ul><li><code>::Int</code>: the bandwidth of <code>A</code>.</li></ul><p><strong>Examples</strong></p><p><code>bandwidth</code> correctly identifies the bandwidth of a pentadiagonal matrix as <span>$2$</span> and does not attempt to find a minimizing permutation upon shuffling of its rows and columns:</p><pre><code class="language-julia-repl hljs">julia&gt; using Random

julia&gt; Random.seed!(242622);

julia&gt; (n, k) = (8, 2);

julia&gt; perm = randperm(n);

julia&gt; A = (!iszero).(random_banded_matrix(8, 2))
8×8 BitMatrix:
 1  0  1  0  0  0  0  0
 1  0  1  1  0  0  0  0
 1  1  1  1  1  0  0  0
 0  1  0  1  1  1  0  0
 0  0  0  1  1  1  1  0
 0  0  0  1  1  1  1  1
 0  0  0  0  1  1  1  1
 0  0  0  0  0  1  0  1

julia&gt; bandwidth(A)
2

julia&gt; A_shuffled = A[perm, perm]
8×8 BitMatrix:
 1  1  1  0  0  0  1  1
 1  1  1  0  0  0  0  1
 1  1  1  0  0  0  1  0
 0  0  1  1  1  1  1  0
 0  0  0  1  1  0  0  0
 0  0  0  1  1  0  1  0
 1  0  1  0  0  1  1  0
 1  0  0  0  0  0  0  1

julia&gt; bandwidth(A_shuffled)
7</code></pre><p><strong>Notes</strong></p><p>Some texts define matrix bandwidth to be the minimum non-negative integer <span>$k$</span> such that <span>$A[i, j] = 0$</span> whenever <span>$|i - j| ≥ k$</span> instead, particularly in more mathematically-minded communities. Effectively, this definition treats diagonal matrices as bandwidth <span>$1$</span>, tridiagonal matrices as bandwidth <span>$2$</span>, and so on. Our definition, on the other hand, is more common in computer science contexts, treating diagonal matrices as bandwidth <span>$0$</span> and tridiagonal matrices as bandwidth <span>$1$</span>. (Both definitions, however, agree that the bandwidth of an empty matrix is simply <span>$0$</span>.)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/core.jl#L86-L155">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.minimize_bandwidth-Union{Tuple{AbstractMatrix{T}}, Tuple{T}, Tuple{AbstractMatrix{T}, MatrixBandwidth.AbstractSolver}} where T&lt;:Number" href="#MatrixBandwidth.minimize_bandwidth-Union{Tuple{AbstractMatrix{T}}, Tuple{T}, Tuple{AbstractMatrix{T}, MatrixBandwidth.AbstractSolver}} where T&lt;:Number"><code>MatrixBandwidth.minimize_bandwidth</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">minimize_bandwidth(A, solver=ReverseCuthillMcKee()) -&gt; BandwidthResult</code></pre><p>Minimize the matrix bandwidth of <code>A</code> using the algorithm defined by <code>solver</code>.</p><p>The <em>bandwidth</em> of a square matrix <span>$A$</span> is the minimum non-negative integer <span>$k ∈ ℕ$</span> such that <span>$A[i, j] = 0$</span> whenever <span>$|i - j| &gt; k$</span>. Equivalently, <span>$A$</span> has bandwidth <strong>at most</strong> <span>$k$</span> if all entries above the <span>$k$</span>-th superdiagonal and below the <span>$k$</span>-th subdiagonal are zero, and <span>$A$</span> has bandwidth <strong>at least</strong> <span>$k$</span> if there exists any nonzero entry in the <span>$k$</span>-th superdiagonal or subdiagonal.</p><p>This function computes a (near-)optimal ordering <span>$π$</span> of the rows and columns of <span>$A$</span> so that the bandwidth of <span>$PAPᵀ$</span> is minimized, where <span>$P$</span> is the permutation matrix corresponding to <span>$π$</span>. This is known to be an NP-complete problem; however, several heuristic algorithms such as <a href="#MatrixBandwidth.Heuristic.ReverseCuthillMcKee"><code>ReverseCuthillMcKee</code></a> run in polynomial time while still producing near-optimal orderings in practice. Exact methods like <a href="#MatrixBandwidth.Exact.MBPS"><code>MBPS</code></a> are also available, but they are exponential in time complexity and thus only feasible for relatively small matrices.</p><p><strong>Arguments</strong></p><ul><li><code>A::AbstractMatrix{T}</code>: the (square) matrix whose bandwidth is to be minimized.</li><li><code>solver::AbstractSolver</code>: the matrix bandwidth minimization algorithm to use; defaults to   <a href="#MatrixBandwidth.Heuristic.ReverseCuthillMcKee"><code>ReverseCuthillMcKee</code></a>. (See the <a href="#MatrixBandwidth.MatrixBandwidth"><code>MatrixBandwidth</code></a> module documentation   for a full list of supported solvers.)</li></ul><p><strong>Returns</strong></p><ul><li><code>::BandwidthResult</code>: a struct containing the original matrix <code>A</code>, the minimized bandwidth,   the (near-)optimal ordering of the rows and columns, and the algorithm used.</li></ul><p><strong>Examples</strong></p><p>[TODO: Add here once more solvers are implemented]</p><p><strong>Notes</strong></p><p>Some texts define matrix bandwidth to be the minimum non-negative integer <span>$k$</span> such that <span>$A[i, j] = 0$</span> whenever <span>$|i - j| ≥ k$</span> instead, particularly in more mathematically-minded communities. Effectively, this definition treats diagonal matrices as bandwidth <span>$1$</span>, tridiagonal matrices as bandwidth <span>$2$</span>, and so on. Our definition, on the other hand, is more common in computer science contexts, treating diagonal matrices as bandwidth <span>$0$</span> and tridiagonal matrices as bandwidth <span>$1$</span>. (Both definitions, however, agree that the bandwidth of an empty matrix is simply <span>$0$</span>.)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/core.jl#L7-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.random_banded_matrix-Tuple{Int64, Int64}" href="#MatrixBandwidth.random_banded_matrix-Tuple{Int64, Int64}"><code>MatrixBandwidth.random_banded_matrix</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">random_banded_matrix(n, k; p=0.75, rng=default_rng()) -&gt; Matrix{Float64}</code></pre><p>Generate a random <code>n×n</code> matrix with bandwidth exactly <code>k</code> and sparse bands with density <code>p</code>.</p><p>All entries from this matrix will be from the interval <code>[0, 1]</code>. Entries up to the <code>k</code>-th superdiagonal and down to the <code>k</code>-th subdiagonal are nonzero with probability <code>p</code>, and each band has at least one nonzero entry to ensure that the bandwidth is precisely <code>k</code>.</p><p><strong>Arguments</strong></p><ul><li><code>n::Int</code>: the order of the matrix to generate. Must be positive.</li><li><code>k::Int</code>: the desired matrix bandwidth. Must satisfy <code>0 ≤ k &lt; n</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>p::Real=0.75</code>: the band density. Must satisfy <code>0 &lt; p ≤ 1</code>.</li><li><code>rng::AbstractRNG=Random.default_rng()</code>: the random number generator to use. Defaults to   <code>Random.default_rng()</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>::Matrix{Float64}</code>: a random <code>n×n</code> matrix with bandwidth exactly <code>k</code> and sparse bands   with density <code>p</code>.</li></ul><p><strong>Examples</strong></p><p>Generate a <span>$6×6$</span> matrix with bandwidth <span>$1$</span> and the maximum number of nonzero entries:</p><pre><code class="language-julia-repl hljs">julia&gt; using Random

julia&gt; A = random_banded_matrix(6, 1; p=1, rng=MersenneTwister(1228))
6×6 Matrix{Float64}:
 0.918835  0.816296   0.0       0.0        0.0       0.0
 0.182127  0.782844   0.616169  0.0        0.0       0.0
 0.0       0.0445171  0.916205  0.730272   0.0       0.0
 0.0       0.0        0.966811  0.414062   0.210912  0.0
 0.0       0.0        0.0       0.0150353  0.135984  0.558082
 0.0       0.0        0.0       0.0        0.428772  0.329567

julia&gt; bandwidth(A)
1</code></pre><p>Generate a <span>$7×7$</span> matrix with bandwidth <span>$3$</span> and band density <code>0.3</code>:</p><pre><code class="language-julia-repl hljs">julia&gt; using Random

julia&gt; A = random_banded_matrix(7, 3; p=0.3, rng=MersenneTwister(0402))
7×7 Matrix{Float64}:
 0.856072  0.720893  0.0       0.0       0.0       0.0        0.0
 0.0       0.0       0.0       0.646516  0.845229  0.0        0.0
 0.997473  0.773515  0.854375  0.926462  0.21636   0.0        0.0
 0.0       0.516052  0.220979  0.844818  0.0       0.0395003  0.568892
 0.0       0.402696  0.499802  0.0       0.304168  0.237423   0.0
 0.0       0.0       0.0       0.0       0.0       0.0        0.877917
 0.0       0.0       0.0       0.101071  0.0       0.0        0.829221

julia&gt; bandwidth(A)
3</code></pre><p>Generate an <span>$8×8$</span> diagonal (bandwidth <span>$0$</span>) matrix with default band density (<span>$0.75$</span>):</p><pre><code class="language-julia-repl hljs">julia&gt; using Random

julia&gt; A = random_banded_matrix(8, 0; rng=MersenneTwister(0102))
8×8 Matrix{Float64}:
 0.781618  0.0      0.0       0.0  0.0        0.0      0.0       0.0
 0.0       0.56589  0.0       0.0  0.0        0.0      0.0       0.0
 0.0       0.0      0.966643  0.0  0.0        0.0      0.0       0.0
 0.0       0.0      0.0       0.0  0.0        0.0      0.0       0.0
 0.0       0.0      0.0       0.0  0.0412729  0.0      0.0       0.0
 0.0       0.0      0.0       0.0  0.0        0.70196  0.0       0.0
 0.0       0.0      0.0       0.0  0.0        0.0      0.494806  0.0
 0.0       0.0      0.0       0.0  0.0        0.0      0.0       0.227507

julia&gt; bandwidth(A)
0</code></pre><p><strong>Notes</strong></p><p>Users of the <a href="#MatrixBandwidth.MatrixBandwidth"><code>MatrixBandwidth</code></a> package may find this function useful when generating random test data for whatever frameworks, algorithms, etc. they are implementing.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/utils.jl#L61-L141">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Exact" href="#MatrixBandwidth.Exact"><code>MatrixBandwidth.Exact</code></a> — <span class="docstring-category">Module</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MatrixBandwidth.Exact</code></pre><p>Exact solvers for matrix bandwidth minimization.</p><p>This submodule is part of the <a href="https://github.com/Luis-Varona/MatrixBandwidth.jl">MatrixBandwidth.jl</a> package.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Exact/Exact.jl#L7-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Exact.MBID" href="#MatrixBandwidth.Exact.MBID"><code>MatrixBandwidth.Exact.MBID</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MBID &lt;: ExactSolver &lt;: AbstractSolver</code></pre><p>TODO: Write here</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Exact/mbid.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Exact.MBPS" href="#MatrixBandwidth.Exact.MBPS"><code>MatrixBandwidth.Exact.MBPS</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MBPS &lt;: ExactSolver &lt;: AbstractSolver</code></pre><p>TODO: Write here</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Exact/mbps.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Heuristic" href="#MatrixBandwidth.Heuristic"><code>MatrixBandwidth.Heuristic</code></a> — <span class="docstring-category">Module</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MatrixBandwidth.Heuristic</code></pre><p>Heuristic solvers for matrix bandwidth minimization.</p><p>Heuristic methods are those which aim to produce near-optimal solutions in a more performant manner than exact methods. While precise bandwidth minimization is NP-complete, many heuristic algorithms (such as reverse Cuthill–McKee) run in polynomial time.</p><p>Heuristic algorithms differ from metaheuristic ones in that they do not employ higher-level iterative search frameworks (e.g., stochastic techniques) to survey the global search space and escape local minima; instead, they rely on straightforward deterministic procedures to find good solutions in a single pass.</p><p>The following heuristic algorithms are currently supported:</p><ul><li><a href="#MatrixBandwidth.Heuristic.CuthillMcKee"><code>CuthillMcKee</code></a>: Cuthill–McKee algorithm</li><li><a href="#MatrixBandwidth.Heuristic.ReverseCuthillMcKee"><code>ReverseCuthillMcKee</code></a>: Reverse Cuthill–McKee algorithm</li></ul><p>This submodule is part of the <a href="https://github.com/Luis-Varona/MatrixBandwidth.jl">MatrixBandwidth.jl</a> package.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Heuristic/Heuristic.jl#L7-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Heuristic.CuthillMcKee" href="#MatrixBandwidth.Heuristic.CuthillMcKee"><code>MatrixBandwidth.Heuristic.CuthillMcKee</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CuthillMcKee &lt;: HeuristicSolver &lt;: AbstractSolver</code></pre><p>The <em>Cuthill–McKee algorithm</em> is a heuristic method for minimizing the bandwidth of a symmetric matrix <span>$A$</span>. It considers the graph <span>$G(A)$</span> whose adjacency matrix is <span>$A$</span> (ignoring self-loops) and performs a breadth-first search of each connected component of <span>$G(A)$</span>, starting from a low-degree node then visiting its neighbors in order of increasing degree. Particularly effective when <span>$A$</span> is sparse, this heuristic typically produces an ordering which induces a matrix bandwidth either equal to or very close to the true minimum [<a href="#CM69">CM69</a>, pp. 157–58].</p><p>We also extend the algorithm to work more generally when <span>$A$</span> is not symmetric by applying it to <span>$A + Aᵀ$</span> instead, as suggested in [<a href="#RS06">RS06</a>, p. 808]. This approach still tends to produce a fairly good ordering, but it is not guaranteed to be as optimal as directly applying Cuthill–McKee to a symmetric input.</p><p><strong>Fields</strong></p><ul><li><code>node_selector::Function</code>: a function that selects a node from some connected component of   the input matrix from which to start the breadth-first search. If no custom heuristic is   specified, this field defaults to <a href="../private_api/#MatrixBandwidth.Heuristic.pseudo_peripheral_node-Tuple{AbstractMatrix{Bool}}"><code>pseudo_peripheral_node</code></a>, which picks a node   &quot;farthest&quot; from the others in the component (not necessarily the lowest-degree node).</li></ul><p><strong>Performance</strong></p><p>Given an <span>$n×n$</span> input matrix <span>$A$</span>, our implementation of Cuthill–McKee runs in <span>$O(n^2)$</span> time, where <span>$n$</span> is the number of rows/columns of the input matrix.</p><p>[<a href="#CG80">CG80</a>] provide a linear-time implementation in the number of nonzero entries of <span>$A$</span>, which is still quadratic when <span>$A$</span> is dense but often much faster when dealing with sparse matrices. However, this would require that <span>$A$</span> be stored as a graph or a sparse matrix, which runs counter to our desire to provide a bandwidth minimization API for all <code>AbstractMatrix{&lt;:Number}</code> types, including dense matrices. (In the future, however, we may indeed consider supporting this more performant implementation for sparse matrices.)</p><p>It was found in [<a href="#Geo71">Geo71</a>, pp. 114–15] that reversing the ordering produced by Cuthill–McKee tends to induce a more optimal bandwidth. This so-called <em>reverse Cuthill–McKee</em> variant is preferred in almost all cases—see <a href="#MatrixBandwidth.Heuristic.ReverseCuthillMcKee"><code>ReverseCuthillMcKee</code></a> and the associated method of <code>_bool_minimal_band_ordering</code> for our implementation.</p><p><strong>Examples</strong></p><p>Cuthill–McKee finds an optimal ordering for an asymmetric <span>$35×35$</span> matrix whose rows and columns have been shuffled:</p><pre><code class="language-julia-repl hljs">julia&gt; using Random

julia&gt; Random.seed!(13);

julia&gt; (n, k) = (35, 3);

julia&gt; A = random_banded_matrix(n, k);

julia&gt; perm = randperm(n);

julia&gt; A_shuffled = A[perm, perm];

julia&gt; iszero.(A) != iszero.(A&#39;) # Proof that the algorithm works for asymmetric input
true

julia&gt; bandwidth(A)
3

julia&gt; bandwidth(A_shuffled) # Much larger after shuffling
31

julia&gt; res = minimize_bandwidth(A_shuffled, CuthillMcKee()) # Finds the true minimum
Results of Matrix Bandwidth Minimization
 * Algorithm: Cuthill–McKee algorithm
 * Approach: Heuristic
 * Minimum bandwidth: 3
 * Original bandwidth: 31
 * Matrix size: 35×35</code></pre><p>Cuthill–McKee finds a near-optimal ordering for an asymmetric <span>$183×183$</span> matrix with multiple (separate) connected components whose rows and columns have been shuffled:</p><pre><code class="language-julia-repl hljs">julia&gt; using Random, SparseArrays

julia&gt; Random.seed!(37452);

julia&gt; (max_cc_size, max_band, p, num_ccs) = (60, 9, 0.2, 7);

julia&gt; components = Vector{SparseMatrixCSC{Float64, Int64}}(undef, num_ccs);

julia&gt; for i in 1:num_ccs # Some components may themselves be disconnected
           cc_size = rand(1:max_cc_size);
           cc_band = rand(0:min(max_band, cc_size - 1));
           components[i] = sparse(random_banded_matrix(cc_size, cc_band; p=p));
       end

julia&gt; A = blockdiag(components...); # `A` has least 7 connected components

julia&gt; perm = randperm(sum(map(cc -&gt; size(cc, 1), components)));

julia&gt; A_shuffled = A[perm, perm];

julia&gt; res = minimize_bandwidth(A_shuffled, CuthillMcKee());

julia&gt; A # The original matrix
183×183 SparseMatrixCSC{Float64, Int64} with 408 stored entries:
⎡⣜⣹⡤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤
⎢⠀⠪⣿⣭⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠁⠄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠑⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢱⢆⢠⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠳⢽⡇⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⠽⡺⠦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠓⣷⣇⣂⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠣⣏⣾⣂⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠲⣻⣾⣤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠋⡏⢷⣦⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠛⠾⠠⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠑⠄⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⢽⣟⣀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⠾⠶⡤⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠊⠾⡻⣦⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠃⡟⣵⢄⠀⎥
⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠱⢹⣣⎦

julia&gt; A_shuffled # A far-from-optimal ordering of `A`
183×183 SparseMatrixCSC{Float64, Int64} with 408 stored entries:
⎡⠁⢄⡂⠀⠀⢀⠀⠀⠀⠂⠂⢀⠀⢀⠀⠀⠀⠀⠀⢀⠐⠠⠂⠀⠀⠀⢀⠀⠀⠀⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⎤
⎢⠀⠈⠁⠤⠀⠄⠀⠀⠀⠀⠠⠀⢀⠀⠀⠁⠡⠀⠀⠀⠈⠀⠀⡀⠀⡀⠒⠀⠀⠘⠀⠀⠀⠀⡀⠀⠀⠀⠀⡄⎥
⎢⠀⢠⠀⠀⠁⢄⠈⠀⠀⠀⠀⠀⠄⠀⠀⠀⠠⠀⠐⠁⠀⠠⠁⠠⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠤⠀⠀⎥
⎢⠀⠀⠀⠀⠢⠀⠁⠅⠀⠀⠐⢐⠀⠂⠀⠀⠀⠀⠐⠐⠀⠐⠀⠀⠀⠀⠀⠀⠀⠄⠠⠀⠀⠐⠐⠀⠀⠀⠀⠂⎥
⎢⠀⠀⠀⠀⠉⢀⢀⠁⠁⢀⠀⡈⠁⠐⠀⠀⠐⠀⠈⠀⠀⡀⠀⠀⠀⠀⠈⠀⠀⠈⠀⠀⠂⠀⠀⠐⠐⠀⠐⠀⎥
⎢⠀⢀⢀⠀⡀⠁⠀⠀⠈⠀⠑⣀⡀⠀⠀⠀⠐⠀⠀⠈⠀⠀⠈⠇⠀⠀⠐⠀⠀⠀⠀⠀⠠⠀⠀⠄⠁⠂⠁⠐⎥
⎢⠀⠀⠀⠐⠀⠈⠠⠀⠀⠈⡀⠀⢐⠌⠀⡁⡀⠐⠀⠰⠀⢀⠀⠄⠀⠄⡀⠀⠀⠀⠐⠔⡁⠀⠀⠀⠀⠀⡀⠄⎥
⎢⠀⠀⠀⠠⠄⠀⠀⠀⠀⠀⠁⠀⠀⠀⠐⢈⠤⡀⠀⠄⠈⠀⠀⠀⠀⠄⠀⠁⠀⠀⠁⠀⠀⠀⠀⠀⠀⠀⢀⠀⎥
⎢⠈⠀⠁⢀⠀⠀⠀⠀⠐⠀⢀⠀⠀⠂⠀⠠⠑⠀⠀⠀⠈⠂⠀⠂⠐⡀⢀⠤⠂⠀⠐⠀⠀⠀⠐⡠⠀⠂⠀⠀⎥
⎢⢀⠀⠀⢀⠆⡠⠂⠀⠂⠀⠀⠀⠄⠀⠀⠂⠀⠁⠀⢀⠀⠔⠀⠀⠀⡀⠀⠀⠂⢂⠀⠀⠀⢀⠀⠀⠀⢀⠀⠃⎥
⎢⠐⡀⠂⡀⠀⠀⢀⠀⢄⠠⡀⠀⠀⠀⠀⠀⠀⠈⡁⡀⠀⢤⠒⡀⠀⠀⠀⠈⠀⠀⠠⠀⠀⠐⠀⠁⠀⠀⡀⠀⎥
⎢⠀⠀⠀⠠⠠⠀⠀⠀⠁⠀⠂⠈⠀⠀⠀⡀⠁⢤⠄⠈⠈⠠⠀⠄⠈⠀⠀⠠⠀⠀⠀⠀⠈⠀⠠⠌⡀⠈⠠⠀⎥
⎢⠀⠐⠀⠀⠀⠀⠠⠀⠀⠀⠠⠀⠀⠀⠀⠀⠄⠁⠀⠲⠀⠀⠀⠀⠐⠀⠂⠀⠀⠀⠀⠐⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠠⠀⠀⠐⠀⠀⠀⠈⠀⠀⠀⠀⠀⡀⠀⠀⡀⠀⠀⡄⠀⠀⠐⠄⠀⠀⠐⠀⠊⠀⠐⡢⠈⠀⠀⢀⎥
⎢⠀⠀⡠⠀⠁⡀⠌⠄⠀⠀⠀⡀⠀⠀⠀⠀⠀⠀⠌⠀⠀⠀⠀⠀⠀⠀⣀⠀⠑⠀⢀⡀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⡐⢂⠀⠅⠀⠂⠀⠀⠀⠀⠀⠀⠄⠀⠀⢀⠀⠠⡀⠂⠄⡀⠀⠀⠂⠀⠀⠘⠑⠀⠀⠀⠀⠀⠠⠢⠀⠀⎥
⎢⠀⠀⠂⠀⠠⢀⠀⠀⠀⠀⠀⢀⠀⠄⠀⠄⠀⠄⠄⠠⢀⠀⠀⠀⠀⠀⠁⠠⠀⢘⠀⠠⠐⠀⠁⠀⠀⢀⠠⠀⎥
⎢⠀⢂⠀⠀⠀⠀⠀⠀⠐⠀⠀⡀⡀⠀⠀⢀⠀⠈⠀⠀⠀⠀⡀⠂⠐⠀⠸⠨⡀⠀⠀⠀⢀⡀⠱⠄⠈⠀⠀⠈⎥
⎢⢀⠐⠀⠠⠀⠂⠈⠀⠀⠀⠀⠀⠂⠡⠀⠄⠀⠀⠀⢠⠀⠠⡀⠀⠀⠀⠀⠀⠀⢐⠀⠀⠀⠐⠂⠀⠁⢐⠂⠀⎥
⎣⠀⠀⠀⠄⠀⢀⠀⠀⠀⠀⠁⠀⠠⠀⠀⠤⠀⠂⠤⠀⠀⠀⠀⠂⠈⠀⠀⠐⠀⠀⠀⠀⠀⠀⠠⠠⠈⠄⠀⠄⎦

julia&gt; A_shuffled[res.ordering, res.ordering] # A near-optimal reordering of `A_shuffled`
183×183 SparseMatrixCSC{Float64, Int64} with 408 stored entries:
⎡⢱⣶⣤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤
⎢⠀⠹⡵⣉⠄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠈⠢⡤⡤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⢳⡺⣺⠆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠛⡗⡻⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⡎⣽⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⣟⣎⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠘⠬⢅⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢳⣓⠆⠄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢼⣥⣒⢂⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢲⣫⣾⣤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠁⠳⣜⡼⡤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠃⣽⠳⣲⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠐⠛⢄⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⣿⣘⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠁⠃⢦⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⢄⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠓⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⠄⠀⠀⎥
⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⠀⎦

julia&gt; iszero.(A) != iszero.(A&#39;) # Proof that the algorithm works for asymmetric input
true

julia&gt; bandwidth(A)
7

julia&gt; bandwidth(A_shuffled) # Much larger after shuffling
170

julia&gt; res # Gets very close to the true minimum
Results of Matrix Bandwidth Minimization
 * Algorithm: Cuthill–McKee algorithm
 * Approach: Heuristic
 * Minimum bandwidth: 10
 * Original bandwidth: 170
 * Matrix size: 183×183</code></pre><p><strong>Notes</strong></p><p>Note that the <code>node_selector</code> field must be of the form <code>(A::AbstractMatrix{Bool}) -&gt; Integer</code> (i.e., it must take in an boolean matrix and return an integer). If this is not the case, an <code>ArgumentError</code> is thrown upon construction.</p><p>See also the documentation for supertypes <a href="../private_api/#MatrixBandwidth.Heuristic.HeuristicSolver"><code>HeuristicSolver</code></a> and <a href="../private_api/#MatrixBandwidth.AbstractSolver"><code>AbstractSolver</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Heuristic/cuthill_mckee.jl#L7-L198">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Heuristic.ReverseCuthillMcKee" href="#MatrixBandwidth.Heuristic.ReverseCuthillMcKee"><code>MatrixBandwidth.Heuristic.ReverseCuthillMcKee</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ReverseCuthillMcKee &lt;: HeuristicSolver &lt;: AbstractSolver</code></pre><p>The <em>reverse Cuthill–McKee algorithm</em> is a variant of the <em>Cuthill–McKee algorithm</em>—a heuristic method for minimizing the bandwidth of a symmetric matrix <span>$A$</span>. Cuthill–McKee considers the graph <span>$G(A)$</span> whose adjacency matrix is <span>$A$</span> (ignoring self-loops) and performs a breadth-first search of each connected component of <span>$G(A)$</span>, starting from a low-degree node then visiting its neighbors in order of increasing degree. Particularly effective when <span>$A$</span> is sparse, this heuristic typically produces an ordering which induces a matrix bandwidth either equal to or very close to the true minimum [<a href="#CM69">CM69</a>, pp. 157–58]. The reverse Cuthill–McKee algorithm simply reverses the ordering produced by application of Cuthill–McKee; it was found in [<a href="#Geo71">Geo71</a>, pp. 114–15] that this tends to induce an even more optimal bandwidth.</p><p>We also extend the algorithm to work more generally when <span>$A$</span> is not symmetric by applying it to <span>$A + Aᵀ$</span> instead, as suggested in [<a href="#RS06">RS06</a>, p. 808]. This approach still tends to produce a fairly good ordering, but it is not guaranteed to be as optimal as directly applying reverse Cuthill–McKee to a symmetric input.</p><p><strong>Performance</strong></p><p>Given an <span>$n×n$</span> input matrix <span>$A$</span>, our implementation of Cuthill–McKee runs in <span>$O(n^2)$</span> time, where <span>$n$</span> is the number of rows/columns of the input matrix.</p><p>[<a href="#CG80">CG80</a>] provide a linear-time implementation in the number of nonzero entries of <span>$A$</span>, which is still quadratic when <span>$A$</span> is dense but often much faster when dealing with sparse matrices. However, this would require that <span>$A$</span> be stored as a graph or a sparse matrix, which runs counter to our desire to provide a bandwidth minimization API for all <code>AbstractMatrix{&lt;:Number}</code> types, including dense matrices. (In the future, however, we may indeed consider supporting this more performant implementation for sparse matrices.)</p><p><strong>Fields</strong></p><ul><li><code>node_selector::Function</code>: a function that selects a node from some connected component of   the input matrix from which to start the breadth-first search. If no custom heuristic is   specified, this field defaults to <a href="../private_api/#MatrixBandwidth.Heuristic.pseudo_peripheral_node-Tuple{AbstractMatrix{Bool}}"><code>pseudo_peripheral_node</code></a>, which picks a node   &quot;farthest&quot; from the others in the component (not necessarily the lowest-degree node).</li></ul><p><strong>Examples</strong></p><p>Reverse Cuthill–McKee finds an optimal ordering for an asymmetric <span>$45×45$</span> matrix whose rows and columns have been shuffled:</p><pre><code class="language-julia-repl hljs">julia&gt; using Random

julia&gt; Random.seed!(87);

julia&gt; (n, k) = (45, 4);

julia&gt; A = random_banded_matrix(n, k);

julia&gt; perm = randperm(n);

julia&gt; A_shuffled = A[perm, perm];

julia&gt; iszero.(A) != iszero.(A&#39;) # Proof that the algorithm works for asymmetric input
true

julia&gt; bandwidth(A)
4

julia&gt; bandwidth(A_shuffled) # Much larger after shuffling
44

julia&gt; res = minimize_bandwidth(A_shuffled, ReverseCuthillMcKee()) # Finds the true minimum
Results of Matrix Bandwidth Minimization
 * Algorithm: Reverse Cuthill–McKee algorithm
 * Approach: Heuristic
 * Minimum bandwidth: 4
 * Original bandwidth: 44
 * Matrix size: 45×45</code></pre><p>Reverse Cuthill–McKee finds a near-optimal ordering for an asymmetric <span>$251×251$</span> matrix with multiple (separate) connected components whose rows and columns have been shuffled:</p><pre><code class="language-julia-repl hljs">julia&gt; using Random, SparseArrays

julia&gt; Random.seed!(5747);

julia&gt; (max_cc_size, max_band, p, num_ccs) = (60, 9, 0.2, 8);

julia&gt; components = Vector{SparseMatrixCSC{Float64, Int64}}(undef, num_ccs);

julia&gt; for i in 1:num_ccs # Some components may themselves be disconnected
           cc_size = rand(0:max_cc_size);
           cc_band = rand(1:min(max_band, cc_size - 1));
           components[i] = sparse(random_banded_matrix(cc_size, cc_band; p=p));
       end

julia&gt; A = blockdiag(components...); # `A` has least 8 connected components

julia&gt; perm = randperm(sum(map(cc -&gt; size(cc, 1), components)));

julia&gt; A_shuffled = A[perm, perm];

julia&gt; res = minimize_bandwidth(A_shuffled, ReverseCuthillMcKee());

julia&gt; A # The original matrix
251×251 SparseMatrixCSC{Float64, Int64} with 617 stored entries:
⎡⢛⣷⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤
⎢⠀⠈⢿⣇⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠘⠻⣦⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠉⢿⣶⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠘⠹⣢⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢿⣷⢄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠬⣣⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠿⣵⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣦⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⢛⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢾⣳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢻⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⡓⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⡥⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠾⢇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⡆⡀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠿⣡⡄⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠻⣤⡀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠳⣆⡀⠀⎥
⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣆⎦

julia&gt; A_shuffled # A far-from-optimal ordering of `A`
251×251 SparseMatrixCSC{Float64, Int64} with 617 stored entries:
⎡⠑⢅⠀⠀⡠⠁⡀⠀⠨⢀⠀⠀⠄⠀⠀⡂⠀⡁⠒⢄⠀⠂⢀⠀⠀⠐⣁⢀⠀⢂⠠⠁⡠⠢⢀⡂⠀⠀⢀⡀⎤
⎢⠀⠀⠩⢂⠀⠀⠀⣀⠈⠈⠁⠀⠀⠠⠈⠀⠀⠀⠄⠀⠀⠒⠀⠀⠀⠀⠀⠈⠀⠁⠈⡀⠀⠀⠠⡀⠀⠀⠄⠀⎥
⎢⡀⠦⠀⠀⠑⠄⠀⠀⠠⠀⠠⠄⠀⠀⢀⠌⠀⠀⠀⠈⢠⠀⠁⡀⠢⠀⠀⠠⡁⠂⡔⡀⠁⠀⢂⠀⠠⢁⠀⠁⎥
⎢⠠⠈⠄⣠⠐⠀⠐⢄⡁⠀⠀⡀⢰⠀⠁⠀⠈⠀⠀⠀⢀⠂⡀⠀⢀⠀⠁⠂⢂⠈⠀⢀⠀⠀⠀⠈⠀⠈⡀⡠⎥
⎢⠀⠀⠀⠄⠀⡈⠀⠀⠵⠂⠀⠀⠀⢠⠀⠂⠒⠀⠀⠀⠐⠠⠀⠀⢄⠀⣐⠆⠀⠐⠀⠠⠀⠀⠨⠄⠦⡀⠀⡀⎥
⎢⠠⠀⢀⠀⠀⠀⠀⠠⠀⠈⡐⢌⠀⠂⠂⠈⠀⠔⠀⠁⣀⠀⢀⠀⠠⠀⠀⠐⠀⠀⠐⠁⠀⠄⠀⠂⠀⠀⠂⢀⎥
⎢⢨⢁⠀⠠⠀⠀⠀⠄⡀⡀⠀⠁⠂⠂⠁⠐⢀⠀⠀⢁⠐⠘⢂⠀⠀⠀⡀⠀⠔⠀⠀⠀⠀⠀⠀⠀⠀⠀⠁⠀⎥
⎢⠢⠂⠂⡀⠀⠔⠀⢂⠀⠀⢨⠀⢀⠀⠐⠐⠀⠀⠀⠂⠐⠄⠈⠀⡀⠂⠁⠤⢀⠂⢀⠀⡀⢀⠀⠀⠀⠀⠀⠀⎥
⎢⠂⠀⠀⠀⠀⠀⠂⠀⠄⠂⢀⠁⠀⠰⡀⠀⢕⢐⠀⠀⠀⠀⠂⡀⠠⠄⠀⠁⠂⠈⠀⠄⠚⠀⠐⠀⠀⠀⢀⠁⎥
⎢⠀⠄⠀⠁⠁⠀⡀⠀⠀⠀⠁⠀⠄⠘⡀⠠⡊⠀⠒⠄⠐⠂⠀⡂⠁⠀⠂⠀⠀⠀⠀⢄⠁⠀⠀⠀⠀⠀⠠⡀⎥
⎢⠈⠘⠀⠂⠀⠀⠀⠐⠀⠃⠀⠀⠀⡀⠀⠄⠁⠀⠄⠀⠎⢑⠀⢂⠀⠈⠁⠀⠀⢀⠀⢀⠀⢀⠰⡁⠀⠢⠀⠀⎥
⎢⢄⠀⡀⢀⠃⠀⠁⡈⠁⠀⠠⠀⠀⠄⠄⠠⠠⠀⠄⠀⠒⠁⠱⠆⠀⠀⠀⠀⡀⠀⠀⠄⠁⠁⢀⠀⠀⠊⠁⠀⎥
⎢⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠐⠂⠀⠀⡄⠀⠠⠀⠂⠀⠀⠀⠘⠈⠔⠀⠀⠀⠀⠀⠀⠁⠐⢁⢀⠈⡀⠠⠐⎥
⎢⠀⠐⡀⠀⠠⢠⠠⠀⠒⢀⠀⠀⠀⠈⠀⡄⠀⠄⠀⠀⠈⠀⠁⠀⠀⠀⢶⢐⠄⠀⠀⠤⠀⠀⠐⡐⡘⠀⡁⠄⎥
⎢⠁⠀⠒⠀⠀⡀⠐⠁⡂⠀⠀⠀⠔⢀⠈⠀⠈⠀⠀⠒⠀⠄⠂⠀⠒⠀⠀⠀⠀⠄⡀⢐⠐⢄⡄⠀⢀⠀⡄⠈⎥
⎢⠀⠀⠀⠀⠑⠀⠀⠀⠀⠀⠄⠀⠀⠀⠐⠸⠀⠄⠀⢄⠀⠀⡀⡄⠁⠆⢀⠀⠠⠀⠑⠀⠅⢁⠀⠀⠨⠄⠀⠐⎥
⎢⠠⡂⠀⠀⠀⠂⡀⡀⠀⠁⠀⠀⠀⡠⠀⠀⠐⠀⠀⡉⠀⠀⠀⢀⠐⠀⠉⠀⠀⢄⠀⠁⠐⢔⢀⡀⢂⠀⠀⠀⎥
⎢⢀⠀⠀⠀⠀⠐⠀⠀⠀⠀⠀⠐⠀⠐⠀⠀⢄⠠⠀⠀⠀⠰⢀⡐⠂⢐⠀⠁⠀⠁⠀⠀⢀⠐⠅⢅⠄⢀⠂⠈⎥
⎢⠀⠀⠀⠀⠢⢀⠠⠀⠈⠂⠀⠀⡀⠐⡀⠀⠑⠐⠂⠈⠪⠐⠈⠂⠀⠀⠂⠈⠀⠐⠀⠄⠀⠄⠀⠐⠑⢀⠐⠀⎥
⎣⠀⠀⡀⠁⠐⠀⠀⠈⠀⠉⠉⢀⡀⠀⠁⠀⡈⠀⠀⠂⠀⡀⠀⠀⠀⠂⠀⡀⡄⠀⠁⠂⠁⠀⠀⠀⠀⠀⠑⢆⎦

julia&gt; A_shuffled[res.ordering, res.ordering] # A near-optimal reordering of `A_shuffled`
251×251 SparseMatrixCSC{Float64, Int64} with 617 stored entries:
⎡⠑⢄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤
⎢⠀⠈⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠈⢿⣷⣠⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠈⠹⢷⣷⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠈⢻⡶⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⣾⣧⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⣧⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢛⣟⣦⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠓⢿⣲⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⣷⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠻⡦⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠿⣧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⣶⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⠫⣶⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠿⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠛⢻⣴⡆⠀⠀⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⢱⢶⡄⠀⠀⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠛⣦⣄⠀⠀⠀⎥
⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠾⣷⡀⠀⎥
⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠯⣆⎦

julia&gt; iszero.(A) != iszero.(A&#39;) # Proof that the algorithm works for asymmetric input
true

julia&gt; bandwidth(A)
7

julia&gt; bandwidth(A_shuffled) # Much larger after shuffling
239

julia&gt; res # Gets very close to the true minimum
Results of Matrix Bandwidth Minimization
 * Algorithm: Reverse Cuthill–McKee algorithm
 * Approach: Heuristic
 * Minimum bandwidth: 10
 * Original bandwidth: 239
 * Matrix size: 251×251</code></pre><p><strong>Notes</strong></p><p>Note that the <code>node_selector</code> field must be of the form <code>(A::AbstractMatrix{Bool}) -&gt; Integer</code> (i.e., it must take in an boolean matrix and return an integer). If this is not the case, an <code>ArgumentError</code> is thrown upon construction.</p><p>See also the documentation for supertypes <a href="../private_api/#MatrixBandwidth.Heuristic.HeuristicSolver"><code>HeuristicSolver</code></a> and <a href="../private_api/#MatrixBandwidth.AbstractSolver"><code>AbstractSolver</code></a>, as well as <a href="#MatrixBandwidth.Heuristic.CuthillMcKee"><code>CuthillMcKee</code></a> for the original non-reversed algorithm. (Indeed, the reverse Cuthill–McKee method of <code>_bool_minimal_band_ordering</code> is merely a wrapper around the Cuthill–McKee method.)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Heuristic/reverse_cuthill_mckee.jl#L7-L198">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Metaheuristic" href="#MatrixBandwidth.Metaheuristic"><code>MatrixBandwidth.Metaheuristic</code></a> — <span class="docstring-category">Module</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MatrixBandwidth.Metaheuristic</code></pre><p>Metaheuristic solvers for matrix bandwidth minimization.</p><p>This submodule is part of the <a href="https://github.com/Luis-Varona/MatrixBandwidth.jl">MatrixBandwidth.jl</a> package.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Metaheuristic/Metaheuristic.jl#L7-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Metaheuristic.GRASP" href="#MatrixBandwidth.Metaheuristic.GRASP"><code>MatrixBandwidth.Metaheuristic.GRASP</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GRASP &lt;: MetaheuristicSolver &lt;: AbstractSolver</code></pre><p>TODO: Write here</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Metaheuristic/grasp.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Metaheuristic.GeneticAlgorithm" href="#MatrixBandwidth.Metaheuristic.GeneticAlgorithm"><code>MatrixBandwidth.Metaheuristic.GeneticAlgorithm</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GeneticAlgorithm &lt;: MetaheuristicSolver &lt;: AbstractSolver</code></pre><p>TODO: Write here</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Metaheuristic/genetic_algorithm.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MatrixBandwidth.Metaheuristic.SimulatedAnnealing" href="#MatrixBandwidth.Metaheuristic.SimulatedAnnealing"><code>MatrixBandwidth.Metaheuristic.SimulatedAnnealing</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SimulatedAnnealing &lt;: MetaheuristicSolver &lt;: AbstractSolver</code></pre><p>TODO: Write here</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Luis-Varona/MatrixBandwidth.jl/blob/bab7924a034bf4802a1f23191cd5a7b332af9bcd/src/Metaheuristic/simulated_annealing.jl#L7-L11">source</a></section></article><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation canonical"><dl><dt>[CG80]</dt><dd><div id="CG80">W. M. Chan and A. George. <a href="https://doi.org/10.1007/BF01933580"><em>A linear time implementation of the reverse Cuthill-McKee algorithm</em></a>. <em>BIT Numerical Mathematics</em> <strong>20</strong>, 8–14 (1980).</div></dd><dt>[CM69]</dt><dd><div id="CM69">E. Cuthill and J. McKee. <em>Reducing the bandwidth of sparse symmetric matrices</em>. In: <em>Proceedings of the 24th National Conference of the ACM</em> (Brandon Systems Press, 1969); pp. 157–72.</div></dd><dt>[Geo71]</dt><dd><div id="Geo71">J. A. George. <a href="https://apps.dtic.mil/sti/tr/pdf/AD0726171.pdf"><em>Computer Implementation of the Finite Element Method</em></a>. Ph.D. Thesis, Department of Computer Science, Stanford University (1971).</div></dd><dt>[RS06]</dt><dd><div id="RS06">J. K. Reid and J. A. Scott. <a href="https://doi.org/10.1137/050629938"><em>Reducing the Total Bandwidth of a Sparse Unsymmetric Matrix</em></a>. <em>SIAM Journal on Matrix Analysis and Applications</em> <strong>28</strong>, 805–21 (2006).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../private_api/">Private API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.12.0 on <span class="colophon-date" title="Saturday 14 June 2025 13:40">Saturday 14 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
